{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da53e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f510a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Send the model to the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffe969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms to be applied to the image data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(100),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07cd5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(\"D:/tay/Data/Data_crop/Data_split/classes_image/image_train/\", transform=transform)\n",
    "\n",
    "# Define the data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define the label names\n",
    "label_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb55aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "val_dataset = datasets.ImageFolder(\"D:/tay/Data/Data_crop/Data_split/classes_image/image_test/\", transform=transform)\n",
    "\n",
    "# Define the data loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define the label names\n",
    "label_names = val_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9d0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hand_A', 'hand_A2', 'hand_B', 'hand_C', 'hand_D', 'hand_D2', 'hand_E', 'hand_G', 'hand_H', 'hand_I', 'hand_K', 'hand_L', 'hand_M', 'hand_N', 'hand_O', 'hand_O3', 'hand_P', 'hand_Q', 'hand_R', 'hand_S', 'hand_T', 'hand_U', 'hand_V', 'hand_X', 'hand_Y']\n"
     ]
    }
   ],
   "source": [
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f0aff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(2304*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 25)\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 2304*4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9743937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=25, bias=True)\n",
      ")\n",
      "Epoch [1/1], Step [100/274360], Loss: 3.1079, Train time: 0.08\n",
      "Epoch [1/1], Step [200/274360], Loss: 3.2567, Train time: 0.12\n",
      "Epoch [1/1], Step [300/274360], Loss: 3.2329, Train time: 0.16\n",
      "Epoch [1/1], Step [400/274360], Loss: 3.2315, Train time: 0.20\n",
      "Epoch [1/1], Step [500/274360], Loss: 3.1722, Train time: 0.25\n",
      "Epoch [1/1], Step [600/274360], Loss: 3.1081, Train time: 0.33\n",
      "Epoch [1/1], Step [700/274360], Loss: 3.6629, Train time: 0.45\n",
      "Epoch [1/1], Step [800/274360], Loss: 3.1399, Train time: 0.52\n",
      "Epoch [1/1], Step [900/274360], Loss: 3.1785, Train time: 0.56\n",
      "Epoch [1/1], Step [1000/274360], Loss: 2.5372, Train time: 0.60\n",
      "Epoch [1/1], Step [1100/274360], Loss: 2.3625, Train time: 0.73\n",
      "Epoch [1/1], Step [1200/274360], Loss: 0.8388, Train time: 0.81\n",
      "Epoch [1/1], Step [1300/274360], Loss: 3.2000, Train time: 0.89\n",
      "Epoch [1/1], Step [1400/274360], Loss: 2.0607, Train time: 0.96\n",
      "Epoch [1/1], Step [1500/274360], Loss: 3.0885, Train time: 1.00\n",
      "Epoch [1/1], Step [1600/274360], Loss: 2.2117, Train time: 1.07\n",
      "Epoch [1/1], Step [1700/274360], Loss: 0.8653, Train time: 1.13\n",
      "Epoch [1/1], Step [1800/274360], Loss: 2.3475, Train time: 1.34\n",
      "Epoch [1/1], Step [1900/274360], Loss: 5.9305, Train time: 1.38\n",
      "Epoch [1/1], Step [2000/274360], Loss: 1.6539, Train time: 1.43\n",
      "Epoch [1/1], Step [2100/274360], Loss: 2.9783, Train time: 1.48\n",
      "Epoch [1/1], Step [2200/274360], Loss: 2.3408, Train time: 1.59\n",
      "Epoch [1/1], Step [2300/274360], Loss: 0.9580, Train time: 1.63\n",
      "Epoch [1/1], Step [2400/274360], Loss: 1.6826, Train time: 1.68\n",
      "Epoch [1/1], Step [2500/274360], Loss: 1.2048, Train time: 1.81\n",
      "Epoch [1/1], Step [2600/274360], Loss: 2.3719, Train time: 1.85\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet().to(device)\n",
    "print(model)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 1\n",
    "start_time = time.time()\n",
    "# Loop over the dataset and train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #send data to cuda\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training statistics\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train time: {:.2f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item(), (time.time()-start_time)/60))\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set: {:.2f}%'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506933c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
