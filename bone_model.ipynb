{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da53e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f510a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Send the model to the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffe969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms to be applied to the image data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    #transforms.CenterCrop(100),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cd5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(\"D:/tay/Data/Data_crop/Data_split/classes_bone/bone_train/\", transform=transform)\n",
    "\n",
    "# Define the data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define the label names\n",
    "label_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb55aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "val_dataset = datasets.ImageFolder(\"D:/tay/Data/Data_crop/Data_split/classes_bone/bone_test/\", transform=transform)\n",
    "\n",
    "# Define the data loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define the label names\n",
    "label_names = val_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9d0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hand_A', 'hand_A2', 'hand_B', 'hand_C', 'hand_D', 'hand_D2', 'hand_E', 'hand_G', 'hand_H', 'hand_I', 'hand_K', 'hand_L', 'hand_M', 'hand_N', 'hand_O', 'hand_O3', 'hand_P', 'hand_Q', 'hand_R', 'hand_S', 'hand_T', 'hand_U', 'hand_V', 'hand_X', 'hand_Y']\n"
     ]
    }
   ],
   "source": [
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da00c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(128 * 8 * 8, 25)  # fully-connected layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 128 * 8 * 8)  # flatten the output of the last convolutional layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07272d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=8192, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d9644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/273716], Loss: 1.3975, Train time: 0.14\n",
      "Epoch [1/1], Step [200/273716], Loss: 0.0238, Train time: 0.17\n",
      "Epoch [1/1], Step [300/273716], Loss: 0.1436, Train time: 0.21\n",
      "Epoch [1/1], Step [400/273716], Loss: 1.3123, Train time: 0.24\n",
      "Epoch [1/1], Step [500/273716], Loss: 0.1789, Train time: 0.27\n",
      "Epoch [1/1], Step [600/273716], Loss: 1.7096, Train time: 0.34\n",
      "Epoch [1/1], Step [700/273716], Loss: 0.1510, Train time: 0.39\n",
      "Epoch [1/1], Step [800/273716], Loss: 0.0326, Train time: 0.43\n",
      "Epoch [1/1], Step [900/273716], Loss: 0.1464, Train time: 0.49\n",
      "Epoch [1/1], Step [1000/273716], Loss: 0.4760, Train time: 0.53\n",
      "Epoch [1/1], Step [1100/273716], Loss: 0.1601, Train time: 0.56\n",
      "Epoch [1/1], Step [1200/273716], Loss: 0.0168, Train time: 0.59\n",
      "Epoch [1/1], Step [1300/273716], Loss: 0.0005, Train time: 0.64\n",
      "Epoch [1/1], Step [1400/273716], Loss: 0.0015, Train time: 0.70\n",
      "Epoch [1/1], Step [1500/273716], Loss: 1.5158, Train time: 0.73\n",
      "Epoch [1/1], Step [1600/273716], Loss: 0.1540, Train time: 0.77\n",
      "Epoch [1/1], Step [1700/273716], Loss: 0.1627, Train time: 0.81\n",
      "Epoch [1/1], Step [1800/273716], Loss: 0.0102, Train time: 0.86\n",
      "Epoch [1/1], Step [1900/273716], Loss: 0.2130, Train time: 0.90\n",
      "Epoch [1/1], Step [2000/273716], Loss: 0.0225, Train time: 0.93\n",
      "Epoch [1/1], Step [2100/273716], Loss: 0.0255, Train time: 0.98\n",
      "Epoch [1/1], Step [2200/273716], Loss: 0.1313, Train time: 1.02\n",
      "Epoch [1/1], Step [2300/273716], Loss: 0.0104, Train time: 1.06\n",
      "Epoch [1/1], Step [2400/273716], Loss: 0.0337, Train time: 1.11\n",
      "Epoch [1/1], Step [2500/273716], Loss: 0.0148, Train time: 1.16\n",
      "Epoch [1/1], Step [2600/273716], Loss: 0.0114, Train time: 1.21\n",
      "Epoch [1/1], Step [2700/273716], Loss: 0.0512, Train time: 1.35\n",
      "Epoch [1/1], Step [2800/273716], Loss: 2.2403, Train time: 1.38\n",
      "Epoch [1/1], Step [2900/273716], Loss: 0.0011, Train time: 1.43\n",
      "Epoch [1/1], Step [3000/273716], Loss: 0.1289, Train time: 1.52\n",
      "Epoch [1/1], Step [3100/273716], Loss: 0.1904, Train time: 1.64\n",
      "Epoch [1/1], Step [3200/273716], Loss: 0.0011, Train time: 1.70\n",
      "Epoch [1/1], Step [3300/273716], Loss: 0.0083, Train time: 1.80\n",
      "Epoch [1/1], Step [3400/273716], Loss: 1.7776, Train time: 1.97\n",
      "Epoch [1/1], Step [3500/273716], Loss: 0.0035, Train time: 2.01\n",
      "Epoch [1/1], Step [3600/273716], Loss: 0.1745, Train time: 2.04\n",
      "Epoch [1/1], Step [3700/273716], Loss: 0.2140, Train time: 2.13\n",
      "Epoch [1/1], Step [3800/273716], Loss: 0.0419, Train time: 2.16\n",
      "Epoch [1/1], Step [3900/273716], Loss: 0.0081, Train time: 2.24\n",
      "Epoch [1/1], Step [4000/273716], Loss: 1.6012, Train time: 2.30\n",
      "Epoch [1/1], Step [4100/273716], Loss: 4.3585, Train time: 2.46\n",
      "Epoch [1/1], Step [4200/273716], Loss: 0.0072, Train time: 2.51\n",
      "Epoch [1/1], Step [4300/273716], Loss: 0.0284, Train time: 2.57\n",
      "Epoch [1/1], Step [4400/273716], Loss: 0.0835, Train time: 2.70\n",
      "Epoch [1/1], Step [4500/273716], Loss: 0.5831, Train time: 2.80\n",
      "Epoch [1/1], Step [4600/273716], Loss: 0.0017, Train time: 2.93\n",
      "Epoch [1/1], Step [4700/273716], Loss: 0.3693, Train time: 3.01\n",
      "Epoch [1/1], Step [4800/273716], Loss: 0.5728, Train time: 3.10\n",
      "Epoch [1/1], Step [4900/273716], Loss: 0.0049, Train time: 3.18\n",
      "Epoch [1/1], Step [5000/273716], Loss: 0.0494, Train time: 3.31\n",
      "Epoch [1/1], Step [5100/273716], Loss: 0.0063, Train time: 3.35\n",
      "Epoch [1/1], Step [5200/273716], Loss: 0.0156, Train time: 3.49\n",
      "Epoch [1/1], Step [5300/273716], Loss: 0.0017, Train time: 3.63\n",
      "Epoch [1/1], Step [5400/273716], Loss: 0.0092, Train time: 3.72\n",
      "Epoch [1/1], Step [5500/273716], Loss: 0.0041, Train time: 3.80\n",
      "Epoch [1/1], Step [5600/273716], Loss: 2.4380, Train time: 3.98\n",
      "Epoch [1/1], Step [5700/273716], Loss: 0.0046, Train time: 4.04\n",
      "Epoch [1/1], Step [5800/273716], Loss: 0.0047, Train time: 4.09\n",
      "Epoch [1/1], Step [5900/273716], Loss: 0.1238, Train time: 4.29\n",
      "Epoch [1/1], Step [6000/273716], Loss: 0.1515, Train time: 4.37\n",
      "Epoch [1/1], Step [6100/273716], Loss: 0.0043, Train time: 4.46\n",
      "Epoch [1/1], Step [6200/273716], Loss: 1.9597, Train time: 4.59\n",
      "Epoch [1/1], Step [6300/273716], Loss: 0.0010, Train time: 4.67\n",
      "Epoch [1/1], Step [6400/273716], Loss: 0.5041, Train time: 4.74\n",
      "Epoch [1/1], Step [6500/273716], Loss: 0.0014, Train time: 4.92\n",
      "Epoch [1/1], Step [6600/273716], Loss: 0.0001, Train time: 5.00\n",
      "Epoch [1/1], Step [6700/273716], Loss: 0.0122, Train time: 5.05\n",
      "Epoch [1/1], Step [6800/273716], Loss: 0.0367, Train time: 5.22\n",
      "Epoch [1/1], Step [6900/273716], Loss: 0.3883, Train time: 5.29\n",
      "Epoch [1/1], Step [7000/273716], Loss: 0.0004, Train time: 5.42\n",
      "Epoch [1/1], Step [7100/273716], Loss: 0.0059, Train time: 5.51\n",
      "Epoch [1/1], Step [7200/273716], Loss: 0.6804, Train time: 5.73\n",
      "Epoch [1/1], Step [7300/273716], Loss: 0.0226, Train time: 5.85\n",
      "Epoch [1/1], Step [7400/273716], Loss: 0.1014, Train time: 5.94\n",
      "Epoch [1/1], Step [7500/273716], Loss: 0.0096, Train time: 6.05\n",
      "Epoch [1/1], Step [7600/273716], Loss: 0.0003, Train time: 6.17\n",
      "Epoch [1/1], Step [7700/273716], Loss: 0.0423, Train time: 6.33\n",
      "Epoch [1/1], Step [7800/273716], Loss: 0.0639, Train time: 6.45\n",
      "Epoch [1/1], Step [7900/273716], Loss: 0.0006, Train time: 6.55\n",
      "Epoch [1/1], Step [8000/273716], Loss: 0.0181, Train time: 6.69\n",
      "Epoch [1/1], Step [8100/273716], Loss: 0.0122, Train time: 6.79\n",
      "Epoch [1/1], Step [8200/273716], Loss: 0.0005, Train time: 6.89\n",
      "Epoch [1/1], Step [8300/273716], Loss: 0.0191, Train time: 6.98\n",
      "Epoch [1/1], Step [8400/273716], Loss: 0.0000, Train time: 7.13\n",
      "Epoch [1/1], Step [8500/273716], Loss: 0.1499, Train time: 7.28\n",
      "Epoch [1/1], Step [8600/273716], Loss: 0.0007, Train time: 7.40\n",
      "Epoch [1/1], Step [8700/273716], Loss: 0.0121, Train time: 7.53\n",
      "Epoch [1/1], Step [8800/273716], Loss: 0.0263, Train time: 7.67\n",
      "Epoch [1/1], Step [8900/273716], Loss: 3.2242, Train time: 7.75\n",
      "Epoch [1/1], Step [9000/273716], Loss: 0.0019, Train time: 7.89\n",
      "Epoch [1/1], Step [9100/273716], Loss: 0.0144, Train time: 8.05\n",
      "Epoch [1/1], Step [9200/273716], Loss: 0.0085, Train time: 8.15\n",
      "Epoch [1/1], Step [9300/273716], Loss: 0.0000, Train time: 8.32\n",
      "Epoch [1/1], Step [9400/273716], Loss: 0.0014, Train time: 8.45\n",
      "Epoch [1/1], Step [9500/273716], Loss: 0.0970, Train time: 8.52\n",
      "Epoch [1/1], Step [9600/273716], Loss: 0.0114, Train time: 8.68\n",
      "Epoch [1/1], Step [9700/273716], Loss: 0.0018, Train time: 8.77\n",
      "Epoch [1/1], Step [9800/273716], Loss: 0.0473, Train time: 8.90\n",
      "Epoch [1/1], Step [9900/273716], Loss: 0.0013, Train time: 9.01\n",
      "Epoch [1/1], Step [10000/273716], Loss: 0.0004, Train time: 9.22\n",
      "Epoch [1/1], Step [10100/273716], Loss: 0.0737, Train time: 9.26\n",
      "Epoch [1/1], Step [10200/273716], Loss: 0.2681, Train time: 9.48\n",
      "Epoch [1/1], Step [10300/273716], Loss: 0.0001, Train time: 9.61\n",
      "Epoch [1/1], Step [10400/273716], Loss: 4.7634, Train time: 9.70\n",
      "Epoch [1/1], Step [10500/273716], Loss: 0.0002, Train time: 9.75\n",
      "Epoch [1/1], Step [10600/273716], Loss: 0.0137, Train time: 10.02\n",
      "Epoch [1/1], Step [10700/273716], Loss: 0.0013, Train time: 10.12\n",
      "Epoch [1/1], Step [10800/273716], Loss: 0.0004, Train time: 10.19\n",
      "Epoch [1/1], Step [10900/273716], Loss: 0.0075, Train time: 10.35\n",
      "Epoch [1/1], Step [11000/273716], Loss: 0.0018, Train time: 10.48\n",
      "Epoch [1/1], Step [11100/273716], Loss: 0.1197, Train time: 10.54\n",
      "Epoch [1/1], Step [11200/273716], Loss: 0.0955, Train time: 10.73\n",
      "Epoch [1/1], Step [11300/273716], Loss: 0.0673, Train time: 10.85\n",
      "Epoch [1/1], Step [11400/273716], Loss: 0.0101, Train time: 11.00\n",
      "Epoch [1/1], Step [11500/273716], Loss: 0.0014, Train time: 11.12\n",
      "Epoch [1/1], Step [11600/273716], Loss: 0.0039, Train time: 11.21\n",
      "Epoch [1/1], Step [11700/273716], Loss: 0.0000, Train time: 11.37\n",
      "Epoch [1/1], Step [11800/273716], Loss: 0.0503, Train time: 11.53\n",
      "Epoch [1/1], Step [11900/273716], Loss: 0.0005, Train time: 11.61\n",
      "Epoch [1/1], Step [12000/273716], Loss: 0.0028, Train time: 11.71\n",
      "Epoch [1/1], Step [12100/273716], Loss: 0.0027, Train time: 11.84\n",
      "Epoch [1/1], Step [12200/273716], Loss: 0.1274, Train time: 12.13\n",
      "Epoch [1/1], Step [12300/273716], Loss: 0.0044, Train time: 12.24\n",
      "Epoch [1/1], Step [12400/273716], Loss: 0.0058, Train time: 12.29\n",
      "Epoch [1/1], Step [12500/273716], Loss: 0.0011, Train time: 12.47\n",
      "Epoch [1/1], Step [12600/273716], Loss: 0.0425, Train time: 12.59\n",
      "Epoch [1/1], Step [12700/273716], Loss: 0.0069, Train time: 12.67\n",
      "Epoch [1/1], Step [12800/273716], Loss: 0.0006, Train time: 12.80\n",
      "Epoch [1/1], Step [12900/273716], Loss: 0.2018, Train time: 12.95\n",
      "Epoch [1/1], Step [13000/273716], Loss: 0.0006, Train time: 13.08\n",
      "Epoch [1/1], Step [13100/273716], Loss: 0.0390, Train time: 13.15\n",
      "Epoch [1/1], Step [13200/273716], Loss: 0.0015, Train time: 13.36\n",
      "Epoch [1/1], Step [13300/273716], Loss: 0.0050, Train time: 13.44\n",
      "Epoch [1/1], Step [13400/273716], Loss: 0.1442, Train time: 13.55\n",
      "Epoch [1/1], Step [13500/273716], Loss: 1.1228, Train time: 13.77\n",
      "Epoch [1/1], Step [13600/273716], Loss: 0.0019, Train time: 13.85\n",
      "Epoch [1/1], Step [13700/273716], Loss: 0.0007, Train time: 13.89\n",
      "Epoch [1/1], Step [13800/273716], Loss: 0.0014, Train time: 14.04\n",
      "Epoch [1/1], Step [13900/273716], Loss: 0.0021, Train time: 14.16\n",
      "Epoch [1/1], Step [14000/273716], Loss: 1.0793, Train time: 14.30\n",
      "Epoch [1/1], Step [14100/273716], Loss: 0.0027, Train time: 14.46\n",
      "Epoch [1/1], Step [14200/273716], Loss: 0.0043, Train time: 14.60\n",
      "Epoch [1/1], Step [14300/273716], Loss: 0.0002, Train time: 14.69\n",
      "Epoch [1/1], Step [14400/273716], Loss: 0.0010, Train time: 14.87\n",
      "Epoch [1/1], Step [14500/273716], Loss: 0.0283, Train time: 14.96\n",
      "Epoch [1/1], Step [14600/273716], Loss: 0.0103, Train time: 15.04\n",
      "Epoch [1/1], Step [14700/273716], Loss: 5.0349, Train time: 15.25\n",
      "Epoch [1/1], Step [14800/273716], Loss: 0.0063, Train time: 15.33\n",
      "Epoch [1/1], Step [14900/273716], Loss: 0.0040, Train time: 15.44\n",
      "Epoch [1/1], Step [15000/273716], Loss: 0.0395, Train time: 15.58\n",
      "Epoch [1/1], Step [15100/273716], Loss: 1.2870, Train time: 15.70\n",
      "Epoch [1/1], Step [15200/273716], Loss: 0.0006, Train time: 15.81\n",
      "Epoch [1/1], Step [15300/273716], Loss: 0.0013, Train time: 16.07\n",
      "Epoch [1/1], Step [15400/273716], Loss: 0.0011, Train time: 16.13\n",
      "Epoch [1/1], Step [15500/273716], Loss: 0.0114, Train time: 16.23\n",
      "Epoch [1/1], Step [15600/273716], Loss: 0.0002, Train time: 16.41\n",
      "Epoch [1/1], Step [15700/273716], Loss: 0.0123, Train time: 16.56\n",
      "Epoch [1/1], Step [15800/273716], Loss: 0.0048, Train time: 16.60\n",
      "Epoch [1/1], Step [15900/273716], Loss: 0.0126, Train time: 16.81\n",
      "Epoch [1/1], Step [16000/273716], Loss: 0.0004, Train time: 16.90\n",
      "Epoch [1/1], Step [16100/273716], Loss: 0.0311, Train time: 17.00\n",
      "Epoch [1/1], Step [16200/273716], Loss: 0.0094, Train time: 17.14\n",
      "Epoch [1/1], Step [16300/273716], Loss: 0.1243, Train time: 17.29\n",
      "Epoch [1/1], Step [16400/273716], Loss: 0.0003, Train time: 17.37\n",
      "Epoch [1/1], Step [16500/273716], Loss: 0.0800, Train time: 17.60\n",
      "Epoch [1/1], Step [16600/273716], Loss: 5.8428, Train time: 17.70\n",
      "Epoch [1/1], Step [16700/273716], Loss: 0.0546, Train time: 17.81\n",
      "Epoch [1/1], Step [16800/273716], Loss: 0.0024, Train time: 17.92\n",
      "Epoch [1/1], Step [16900/273716], Loss: 0.0083, Train time: 18.11\n",
      "Epoch [1/1], Step [17000/273716], Loss: 0.0047, Train time: 18.26\n",
      "Epoch [1/1], Step [17100/273716], Loss: 0.0679, Train time: 18.39\n",
      "Epoch [1/1], Step [17200/273716], Loss: 0.0136, Train time: 18.46\n",
      "Epoch [1/1], Step [17300/273716], Loss: 0.0271, Train time: 18.71\n",
      "Epoch [1/1], Step [17400/273716], Loss: 0.0000, Train time: 18.80\n",
      "Epoch [1/1], Step [17500/273716], Loss: 0.0000, Train time: 18.88\n",
      "Epoch [1/1], Step [17600/273716], Loss: 0.0068, Train time: 19.11\n",
      "Epoch [1/1], Step [17700/273716], Loss: 0.0001, Train time: 19.23\n",
      "Epoch [1/1], Step [17800/273716], Loss: 0.0911, Train time: 19.30\n",
      "Epoch [1/1], Step [17900/273716], Loss: 0.0139, Train time: 19.52\n",
      "Epoch [1/1], Step [18000/273716], Loss: 0.0017, Train time: 19.63\n",
      "Epoch [1/1], Step [18100/273716], Loss: 0.0036, Train time: 19.72\n",
      "Epoch [1/1], Step [18200/273716], Loss: 0.0009, Train time: 19.87\n",
      "Epoch [1/1], Step [18300/273716], Loss: 3.8282, Train time: 20.01\n",
      "Epoch [1/1], Step [18400/273716], Loss: 0.1538, Train time: 20.18\n",
      "Epoch [1/1], Step [18500/273716], Loss: 0.0938, Train time: 20.28\n",
      "Epoch [1/1], Step [18600/273716], Loss: 0.0305, Train time: 20.44\n",
      "Epoch [1/1], Step [18700/273716], Loss: 0.0000, Train time: 20.55\n",
      "Epoch [1/1], Step [18800/273716], Loss: 0.1274, Train time: 20.68\n",
      "Epoch [1/1], Step [18900/273716], Loss: 0.0002, Train time: 20.81\n",
      "Epoch [1/1], Step [19000/273716], Loss: 0.0024, Train time: 21.04\n",
      "Epoch [1/1], Step [19100/273716], Loss: 0.3420, Train time: 21.15\n",
      "Epoch [1/1], Step [19200/273716], Loss: 0.0002, Train time: 21.29\n",
      "Epoch [1/1], Step [19300/273716], Loss: 0.2373, Train time: 21.38\n",
      "Epoch [1/1], Step [19400/273716], Loss: 0.2193, Train time: 21.48\n",
      "Epoch [1/1], Step [19500/273716], Loss: 0.0093, Train time: 21.72\n",
      "Epoch [1/1], Step [19600/273716], Loss: 0.0019, Train time: 21.81\n",
      "Epoch [1/1], Step [19700/273716], Loss: 0.0265, Train time: 21.89\n",
      "Epoch [1/1], Step [19800/273716], Loss: 0.0024, Train time: 21.93\n",
      "Epoch [1/1], Step [19900/273716], Loss: 0.0015, Train time: 22.24\n",
      "Epoch [1/1], Step [20000/273716], Loss: 0.5728, Train time: 22.34\n",
      "Epoch [1/1], Step [20100/273716], Loss: 0.0809, Train time: 22.45\n",
      "Epoch [1/1], Step [20200/273716], Loss: 0.0007, Train time: 22.52\n",
      "Epoch [1/1], Step [20300/273716], Loss: 0.0022, Train time: 22.81\n",
      "Epoch [1/1], Step [20400/273716], Loss: 0.0206, Train time: 22.93\n",
      "Epoch [1/1], Step [20500/273716], Loss: 0.0131, Train time: 23.07\n",
      "Epoch [1/1], Step [20600/273716], Loss: 0.0000, Train time: 23.13\n",
      "Epoch [1/1], Step [20700/273716], Loss: 0.0040, Train time: 23.34\n",
      "Epoch [1/1], Step [20800/273716], Loss: 0.0000, Train time: 23.42\n",
      "Epoch [1/1], Step [20900/273716], Loss: 0.0005, Train time: 23.53\n",
      "Epoch [1/1], Step [21000/273716], Loss: 0.0105, Train time: 23.66\n",
      "Epoch [1/1], Step [21100/273716], Loss: 0.0034, Train time: 23.80\n",
      "Epoch [1/1], Step [21200/273716], Loss: 0.0059, Train time: 23.97\n",
      "Epoch [1/1], Step [21300/273716], Loss: 0.0031, Train time: 24.08\n",
      "Epoch [1/1], Step [21400/273716], Loss: 0.0060, Train time: 24.17\n",
      "Epoch [1/1], Step [21500/273716], Loss: 0.0192, Train time: 24.41\n",
      "Epoch [1/1], Step [21600/273716], Loss: 0.0623, Train time: 24.49\n",
      "Epoch [1/1], Step [21700/273716], Loss: 0.3451, Train time: 24.63\n",
      "Epoch [1/1], Step [21800/273716], Loss: 0.0666, Train time: 24.80\n",
      "Epoch [1/1], Step [21900/273716], Loss: 0.0007, Train time: 24.93\n",
      "Epoch [1/1], Step [22000/273716], Loss: 0.0000, Train time: 25.02\n",
      "Epoch [1/1], Step [22100/273716], Loss: 0.0008, Train time: 25.22\n",
      "Epoch [1/1], Step [22200/273716], Loss: 0.0085, Train time: 25.34\n",
      "Epoch [1/1], Step [22300/273716], Loss: 0.0021, Train time: 25.48\n",
      "Epoch [1/1], Step [22400/273716], Loss: 0.0979, Train time: 25.57\n",
      "Epoch [1/1], Step [22500/273716], Loss: 0.0019, Train time: 25.67\n",
      "Epoch [1/1], Step [22600/273716], Loss: 0.0023, Train time: 25.93\n",
      "Epoch [1/1], Step [22700/273716], Loss: 0.0006, Train time: 26.07\n",
      "Epoch [1/1], Step [22800/273716], Loss: 0.0002, Train time: 26.14\n",
      "Epoch [1/1], Step [22900/273716], Loss: 0.3248, Train time: 26.30\n",
      "Epoch [1/1], Step [23000/273716], Loss: 0.0011, Train time: 26.46\n",
      "Epoch [1/1], Step [23100/273716], Loss: 4.1102, Train time: 26.54\n",
      "Epoch [1/1], Step [23200/273716], Loss: 0.0038, Train time: 26.74\n",
      "Epoch [1/1], Step [23300/273716], Loss: 0.0075, Train time: 26.86\n",
      "Epoch [1/1], Step [23400/273716], Loss: 0.0086, Train time: 26.94\n",
      "Epoch [1/1], Step [23500/273716], Loss: 0.0000, Train time: 27.15\n",
      "Epoch [1/1], Step [23600/273716], Loss: 0.0002, Train time: 27.24\n",
      "Epoch [1/1], Step [23700/273716], Loss: 0.0062, Train time: 27.42\n",
      "Epoch [1/1], Step [23800/273716], Loss: 0.0001, Train time: 27.55\n",
      "Epoch [1/1], Step [23900/273716], Loss: 0.0157, Train time: 27.67\n",
      "Epoch [1/1], Step [24000/273716], Loss: 0.0019, Train time: 27.84\n",
      "Epoch [1/1], Step [24100/273716], Loss: 0.0150, Train time: 27.94\n",
      "Epoch [1/1], Step [24200/273716], Loss: 0.0002, Train time: 28.10\n",
      "Epoch [1/1], Step [24300/273716], Loss: 0.0000, Train time: 28.23\n",
      "Epoch [1/1], Step [24400/273716], Loss: 0.0032, Train time: 28.37\n",
      "Epoch [1/1], Step [24500/273716], Loss: 0.0074, Train time: 28.51\n",
      "Epoch [1/1], Step [24600/273716], Loss: 0.0608, Train time: 28.63\n",
      "Epoch [1/1], Step [24700/273716], Loss: 0.0015, Train time: 28.77\n",
      "Epoch [1/1], Step [24800/273716], Loss: 0.0008, Train time: 28.97\n",
      "Epoch [1/1], Step [24900/273716], Loss: 0.0000, Train time: 29.05\n",
      "Epoch [1/1], Step [25000/273716], Loss: 0.0112, Train time: 29.14\n",
      "Epoch [1/1], Step [25100/273716], Loss: 0.0108, Train time: 29.32\n",
      "Epoch [1/1], Step [25200/273716], Loss: 0.0248, Train time: 29.51\n",
      "Epoch [1/1], Step [25300/273716], Loss: 0.0000, Train time: 29.55\n",
      "Epoch [1/1], Step [25400/273716], Loss: 0.0035, Train time: 29.75\n",
      "Epoch [1/1], Step [25500/273716], Loss: 0.0029, Train time: 29.80\n",
      "Epoch [1/1], Step [25600/273716], Loss: 0.1190, Train time: 29.96\n",
      "Epoch [1/1], Step [25700/273716], Loss: 0.0029, Train time: 30.09\n",
      "Epoch [1/1], Step [25800/273716], Loss: 0.0092, Train time: 30.16\n",
      "Epoch [1/1], Step [25900/273716], Loss: 0.0000, Train time: 30.38\n",
      "Epoch [1/1], Step [26000/273716], Loss: 0.0130, Train time: 30.52\n",
      "Epoch [1/1], Step [26100/273716], Loss: 0.0004, Train time: 30.60\n",
      "Epoch [1/1], Step [26200/273716], Loss: 0.0011, Train time: 30.75\n",
      "Epoch [1/1], Step [26300/273716], Loss: 0.0016, Train time: 30.83\n",
      "Epoch [1/1], Step [26400/273716], Loss: 0.0109, Train time: 30.99\n",
      "Epoch [1/1], Step [26500/273716], Loss: 0.0001, Train time: 31.15\n",
      "Epoch [1/1], Step [26600/273716], Loss: 0.1329, Train time: 31.26\n",
      "Epoch [1/1], Step [26700/273716], Loss: 0.0010, Train time: 31.41\n",
      "Epoch [1/1], Step [26800/273716], Loss: 0.0890, Train time: 31.70\n",
      "Epoch [1/1], Step [26900/273716], Loss: 0.0000, Train time: 31.75\n",
      "Epoch [1/1], Step [27000/273716], Loss: 0.0970, Train time: 31.93\n",
      "Epoch [1/1], Step [27100/273716], Loss: 0.0142, Train time: 32.01\n",
      "Epoch [1/1], Step [27200/273716], Loss: 0.0029, Train time: 32.22\n",
      "Epoch [1/1], Step [27300/273716], Loss: 0.0204, Train time: 32.38\n",
      "Epoch [1/1], Step [27400/273716], Loss: 0.0004, Train time: 32.52\n",
      "Epoch [1/1], Step [27500/273716], Loss: 0.0031, Train time: 32.63\n",
      "Epoch [1/1], Step [27600/273716], Loss: 0.0000, Train time: 32.73\n",
      "Epoch [1/1], Step [27700/273716], Loss: 0.0000, Train time: 32.91\n",
      "Epoch [1/1], Step [27800/273716], Loss: 0.0188, Train time: 32.99\n",
      "Epoch [1/1], Step [27900/273716], Loss: 1.6479, Train time: 33.10\n",
      "Epoch [1/1], Step [28000/273716], Loss: 0.0019, Train time: 33.34\n",
      "Epoch [1/1], Step [28100/273716], Loss: 0.0090, Train time: 33.46\n",
      "Epoch [1/1], Step [28200/273716], Loss: 0.0011, Train time: 33.62\n",
      "Epoch [1/1], Step [28300/273716], Loss: 0.0000, Train time: 33.69\n",
      "Epoch [1/1], Step [28400/273716], Loss: 1.2931, Train time: 33.85\n",
      "Epoch [1/1], Step [28500/273716], Loss: 0.0022, Train time: 33.96\n",
      "Epoch [1/1], Step [28600/273716], Loss: 0.0000, Train time: 34.19\n",
      "Epoch [1/1], Step [28700/273716], Loss: 0.0004, Train time: 34.35\n",
      "Epoch [1/1], Step [28800/273716], Loss: 0.0023, Train time: 34.40\n",
      "Epoch [1/1], Step [28900/273716], Loss: 0.0001, Train time: 34.62\n",
      "Epoch [1/1], Step [29000/273716], Loss: 0.0097, Train time: 34.80\n",
      "Epoch [1/1], Step [29100/273716], Loss: 0.0001, Train time: 34.88\n",
      "Epoch [1/1], Step [29200/273716], Loss: 0.0236, Train time: 35.06\n",
      "Epoch [1/1], Step [29300/273716], Loss: 0.0018, Train time: 35.17\n",
      "Epoch [1/1], Step [29400/273716], Loss: 0.0015, Train time: 35.33\n",
      "Epoch [1/1], Step [29500/273716], Loss: 0.0006, Train time: 35.45\n",
      "Epoch [1/1], Step [29600/273716], Loss: 0.0002, Train time: 35.53\n",
      "Epoch [1/1], Step [29700/273716], Loss: 0.0000, Train time: 35.79\n",
      "Epoch [1/1], Step [29800/273716], Loss: 0.3202, Train time: 35.96\n",
      "Epoch [1/1], Step [29900/273716], Loss: 0.0021, Train time: 36.09\n",
      "Epoch [1/1], Step [30000/273716], Loss: 0.0007, Train time: 36.29\n",
      "Epoch [1/1], Step [30100/273716], Loss: 0.0232, Train time: 36.42\n",
      "Epoch [1/1], Step [30200/273716], Loss: 0.0025, Train time: 36.47\n",
      "Epoch [1/1], Step [30300/273716], Loss: 0.0059, Train time: 36.85\n",
      "Epoch [1/1], Step [30400/273716], Loss: 0.0061, Train time: 36.94\n",
      "Epoch [1/1], Step [30500/273716], Loss: 0.0521, Train time: 36.98\n",
      "Epoch [1/1], Step [30600/273716], Loss: 0.0008, Train time: 37.24\n",
      "Epoch [1/1], Step [30700/273716], Loss: 0.0008, Train time: 37.65\n",
      "Epoch [1/1], Step [30800/273716], Loss: 0.0198, Train time: 37.98\n",
      "Epoch [1/1], Step [30900/273716], Loss: 0.0001, Train time: 38.37\n",
      "Epoch [1/1], Step [31000/273716], Loss: 0.0013, Train time: 38.64\n",
      "Epoch [1/1], Step [31100/273716], Loss: 0.0003, Train time: 38.85\n",
      "Epoch [1/1], Step [31200/273716], Loss: 0.0024, Train time: 39.10\n",
      "Epoch [1/1], Step [31300/273716], Loss: 0.0056, Train time: 39.38\n",
      "Epoch [1/1], Step [31400/273716], Loss: 0.0003, Train time: 39.63\n",
      "Epoch [1/1], Step [31500/273716], Loss: 0.0095, Train time: 39.87\n",
      "Epoch [1/1], Step [31600/273716], Loss: 0.0031, Train time: 40.09\n",
      "Epoch [1/1], Step [31700/273716], Loss: 0.3553, Train time: 40.40\n",
      "Epoch [1/1], Step [31800/273716], Loss: 0.0005, Train time: 40.60\n",
      "Epoch [1/1], Step [31900/273716], Loss: 0.1928, Train time: 40.79\n",
      "Epoch [1/1], Step [32000/273716], Loss: 0.0196, Train time: 40.88\n",
      "Epoch [1/1], Step [32100/273716], Loss: 0.0051, Train time: 40.94\n",
      "Epoch [1/1], Step [32200/273716], Loss: 0.0171, Train time: 41.13\n",
      "Epoch [1/1], Step [32300/273716], Loss: 0.0000, Train time: 41.17\n",
      "Epoch [1/1], Step [32400/273716], Loss: 0.0005, Train time: 41.27\n",
      "Epoch [1/1], Step [32500/273716], Loss: 0.0001, Train time: 41.34\n",
      "Epoch [1/1], Step [32600/273716], Loss: 0.0000, Train time: 41.55\n",
      "Epoch [1/1], Step [32700/273716], Loss: 0.0002, Train time: 41.65\n",
      "Epoch [1/1], Step [32800/273716], Loss: 0.0001, Train time: 41.72\n",
      "Epoch [1/1], Step [32900/273716], Loss: 0.0001, Train time: 41.78\n",
      "Epoch [1/1], Step [33000/273716], Loss: 0.0004, Train time: 41.93\n",
      "Epoch [1/1], Step [33100/273716], Loss: 0.0029, Train time: 42.16\n",
      "Epoch [1/1], Step [33200/273716], Loss: 0.0001, Train time: 42.23\n",
      "Epoch [1/1], Step [33300/273716], Loss: 0.0445, Train time: 42.31\n",
      "Epoch [1/1], Step [33400/273716], Loss: 0.0002, Train time: 42.49\n",
      "Epoch [1/1], Step [33500/273716], Loss: 0.0002, Train time: 42.67\n",
      "Epoch [1/1], Step [33600/273716], Loss: 1.8638, Train time: 42.84\n",
      "Epoch [1/1], Step [33700/273716], Loss: 0.0009, Train time: 42.91\n",
      "Epoch [1/1], Step [33800/273716], Loss: 0.0001, Train time: 43.02\n",
      "Epoch [1/1], Step [33900/273716], Loss: 0.2392, Train time: 43.19\n",
      "Epoch [1/1], Step [34000/273716], Loss: 0.0003, Train time: 43.25\n",
      "Epoch [1/1], Step [34100/273716], Loss: 0.0009, Train time: 43.39\n",
      "Epoch [1/1], Step [34200/273716], Loss: 0.1984, Train time: 43.55\n",
      "Epoch [1/1], Step [34300/273716], Loss: 0.0505, Train time: 43.59\n",
      "Epoch [1/1], Step [34400/273716], Loss: 0.1769, Train time: 43.74\n",
      "Epoch [1/1], Step [34500/273716], Loss: 0.0005, Train time: 43.86\n",
      "Epoch [1/1], Step [34600/273716], Loss: 0.0019, Train time: 44.05\n",
      "Epoch [1/1], Step [34700/273716], Loss: 0.1063, Train time: 44.08\n",
      "Epoch [1/1], Step [34800/273716], Loss: 0.0061, Train time: 44.21\n",
      "Epoch [1/1], Step [34900/273716], Loss: 0.0198, Train time: 44.31\n",
      "Epoch [1/1], Step [35000/273716], Loss: 0.0000, Train time: 44.46\n",
      "Epoch [1/1], Step [35100/273716], Loss: 0.0000, Train time: 44.55\n",
      "Epoch [1/1], Step [35200/273716], Loss: 0.0001, Train time: 44.71\n",
      "Epoch [1/1], Step [35300/273716], Loss: 0.0008, Train time: 44.87\n",
      "Epoch [1/1], Step [35400/273716], Loss: 0.0002, Train time: 44.93\n",
      "Epoch [1/1], Step [35500/273716], Loss: 0.0000, Train time: 45.12\n",
      "Epoch [1/1], Step [35600/273716], Loss: 0.0002, Train time: 45.26\n",
      "Epoch [1/1], Step [35700/273716], Loss: 0.0001, Train time: 45.34\n",
      "Epoch [1/1], Step [35800/273716], Loss: 0.0053, Train time: 45.41\n",
      "Epoch [1/1], Step [35900/273716], Loss: 0.0011, Train time: 45.62\n",
      "Epoch [1/1], Step [36000/273716], Loss: 0.0013, Train time: 45.78\n",
      "Epoch [1/1], Step [36100/273716], Loss: 0.0072, Train time: 45.86\n",
      "Epoch [1/1], Step [36200/273716], Loss: 0.0002, Train time: 45.96\n",
      "Epoch [1/1], Step [36300/273716], Loss: 0.0001, Train time: 46.17\n",
      "Epoch [1/1], Step [36400/273716], Loss: 0.0111, Train time: 46.25\n",
      "Epoch [1/1], Step [36500/273716], Loss: 0.0000, Train time: 46.35\n",
      "Epoch [1/1], Step [36600/273716], Loss: 0.0000, Train time: 46.54\n",
      "Epoch [1/1], Step [36700/273716], Loss: 0.0000, Train time: 46.84\n",
      "Epoch [1/1], Step [36800/273716], Loss: 0.0001, Train time: 46.91\n",
      "Epoch [1/1], Step [36900/273716], Loss: 0.0032, Train time: 47.15\n",
      "Epoch [1/1], Step [37000/273716], Loss: 0.0000, Train time: 47.27\n",
      "Epoch [1/1], Step [37100/273716], Loss: 0.4429, Train time: 47.42\n",
      "Epoch [1/1], Step [37200/273716], Loss: 0.0342, Train time: 47.56\n",
      "Epoch [1/1], Step [37300/273716], Loss: 0.0050, Train time: 47.63\n",
      "Epoch [1/1], Step [37400/273716], Loss: 0.0006, Train time: 47.83\n",
      "Epoch [1/1], Step [37500/273716], Loss: 0.0005, Train time: 47.93\n",
      "Epoch [1/1], Step [37600/273716], Loss: 0.0002, Train time: 48.02\n",
      "Epoch [1/1], Step [37700/273716], Loss: 0.0037, Train time: 48.09\n",
      "Epoch [1/1], Step [37800/273716], Loss: 0.0013, Train time: 48.33\n",
      "Epoch [1/1], Step [37900/273716], Loss: 0.0004, Train time: 48.49\n",
      "Epoch [1/1], Step [38000/273716], Loss: 0.0112, Train time: 48.57\n",
      "Epoch [1/1], Step [38100/273716], Loss: 0.0035, Train time: 48.73\n",
      "Epoch [1/1], Step [38200/273716], Loss: 0.0012, Train time: 48.84\n",
      "Epoch [1/1], Step [38300/273716], Loss: 0.0109, Train time: 48.98\n",
      "Epoch [1/1], Step [38400/273716], Loss: 0.0012, Train time: 49.05\n",
      "Epoch [1/1], Step [38500/273716], Loss: 0.0000, Train time: 49.27\n",
      "Epoch [1/1], Step [38600/273716], Loss: 0.0064, Train time: 49.42\n",
      "Epoch [1/1], Step [38700/273716], Loss: 0.0040, Train time: 49.49\n",
      "Epoch [1/1], Step [38800/273716], Loss: 0.0167, Train time: 49.71\n",
      "Epoch [1/1], Step [38900/273716], Loss: 0.0009, Train time: 49.87\n",
      "Epoch [1/1], Step [39000/273716], Loss: 0.0000, Train time: 50.02\n",
      "Epoch [1/1], Step [39100/273716], Loss: 0.0244, Train time: 50.09\n",
      "Epoch [1/1], Step [39200/273716], Loss: 0.0091, Train time: 50.24\n",
      "Epoch [1/1], Step [39300/273716], Loss: 0.0002, Train time: 50.35\n",
      "Epoch [1/1], Step [39400/273716], Loss: 0.0001, Train time: 50.62\n",
      "Epoch [1/1], Step [39500/273716], Loss: 0.0007, Train time: 50.65\n",
      "Epoch [1/1], Step [39600/273716], Loss: 0.0043, Train time: 50.78\n",
      "Epoch [1/1], Step [39700/273716], Loss: 0.0257, Train time: 50.96\n",
      "Epoch [1/1], Step [39800/273716], Loss: 0.0071, Train time: 51.28\n",
      "Epoch [1/1], Step [39900/273716], Loss: 0.0000, Train time: 51.35\n",
      "Epoch [1/1], Step [40000/273716], Loss: 0.0009, Train time: 51.43\n",
      "Epoch [1/1], Step [40100/273716], Loss: 0.0003, Train time: 51.63\n",
      "Epoch [1/1], Step [40200/273716], Loss: 0.0126, Train time: 51.70\n",
      "Epoch [1/1], Step [40300/273716], Loss: 0.0618, Train time: 51.79\n",
      "Epoch [1/1], Step [40400/273716], Loss: 0.0103, Train time: 51.89\n",
      "Epoch [1/1], Step [40500/273716], Loss: 0.0008, Train time: 52.04\n",
      "Epoch [1/1], Step [40600/273716], Loss: 0.0493, Train time: 52.09\n",
      "Epoch [1/1], Step [40700/273716], Loss: 0.0043, Train time: 52.26\n",
      "Epoch [1/1], Step [40800/273716], Loss: 0.0000, Train time: 52.42\n",
      "Epoch [1/1], Step [40900/273716], Loss: 3.2388, Train time: 52.57\n",
      "Epoch [1/1], Step [41000/273716], Loss: 0.1785, Train time: 52.67\n",
      "Epoch [1/1], Step [41100/273716], Loss: 0.6480, Train time: 52.91\n",
      "Epoch [1/1], Step [41200/273716], Loss: 0.0003, Train time: 52.96\n",
      "Epoch [1/1], Step [41300/273716], Loss: 0.0018, Train time: 53.16\n",
      "Epoch [1/1], Step [41400/273716], Loss: 0.0003, Train time: 53.26\n",
      "Epoch [1/1], Step [41500/273716], Loss: 0.0018, Train time: 53.41\n",
      "Epoch [1/1], Step [41600/273716], Loss: 0.0005, Train time: 53.45\n",
      "Epoch [1/1], Step [41700/273716], Loss: 0.0002, Train time: 53.60\n",
      "Epoch [1/1], Step [41800/273716], Loss: 0.0039, Train time: 53.76\n",
      "Epoch [1/1], Step [41900/273716], Loss: 0.0012, Train time: 53.83\n",
      "Epoch [1/1], Step [42000/273716], Loss: 0.0002, Train time: 53.90\n",
      "Epoch [1/1], Step [42100/273716], Loss: 0.0621, Train time: 54.12\n",
      "Epoch [1/1], Step [42200/273716], Loss: 0.0085, Train time: 54.24\n",
      "Epoch [1/1], Step [42300/273716], Loss: 0.0001, Train time: 54.30\n",
      "Epoch [1/1], Step [42400/273716], Loss: 0.0215, Train time: 54.59\n",
      "Epoch [1/1], Step [42500/273716], Loss: 0.1252, Train time: 54.78\n",
      "Epoch [1/1], Step [42600/273716], Loss: 0.0018, Train time: 54.87\n",
      "Epoch [1/1], Step [42700/273716], Loss: 0.1940, Train time: 55.06\n",
      "Epoch [1/1], Step [42800/273716], Loss: 0.0005, Train time: 55.19\n",
      "Epoch [1/1], Step [42900/273716], Loss: 0.0565, Train time: 55.27\n",
      "Epoch [1/1], Step [43000/273716], Loss: 0.0001, Train time: 55.34\n",
      "Epoch [1/1], Step [43100/273716], Loss: 0.0007, Train time: 55.55\n",
      "Epoch [1/1], Step [43200/273716], Loss: 0.1100, Train time: 55.71\n",
      "Epoch [1/1], Step [43300/273716], Loss: 0.0000, Train time: 55.77\n",
      "Epoch [1/1], Step [43400/273716], Loss: 0.0007, Train time: 55.92\n",
      "Epoch [1/1], Step [43500/273716], Loss: 0.0001, Train time: 56.10\n",
      "Epoch [1/1], Step [43600/273716], Loss: 0.0017, Train time: 56.19\n",
      "Epoch [1/1], Step [43700/273716], Loss: 0.0015, Train time: 56.25\n",
      "Epoch [1/1], Step [43800/273716], Loss: 0.7213, Train time: 56.50\n",
      "Epoch [1/1], Step [43900/273716], Loss: 0.0001, Train time: 56.59\n",
      "Epoch [1/1], Step [44000/273716], Loss: 0.3922, Train time: 56.63\n",
      "Epoch [1/1], Step [44100/273716], Loss: 0.0018, Train time: 56.81\n",
      "Epoch [1/1], Step [44200/273716], Loss: 0.0007, Train time: 56.99\n",
      "Epoch [1/1], Step [44300/273716], Loss: 0.0005, Train time: 57.13\n",
      "Epoch [1/1], Step [44400/273716], Loss: 0.0921, Train time: 57.28\n",
      "Epoch [1/1], Step [44500/273716], Loss: 0.1030, Train time: 57.46\n",
      "Epoch [1/1], Step [44600/273716], Loss: 0.0078, Train time: 57.53\n",
      "Epoch [1/1], Step [44700/273716], Loss: 0.0007, Train time: 57.57\n",
      "Epoch [1/1], Step [44800/273716], Loss: 0.0005, Train time: 57.82\n",
      "Epoch [1/1], Step [44900/273716], Loss: 0.0003, Train time: 57.90\n",
      "Epoch [1/1], Step [45000/273716], Loss: 0.0090, Train time: 58.00\n",
      "Epoch [1/1], Step [45100/273716], Loss: 0.0002, Train time: 58.18\n",
      "Epoch [1/1], Step [45200/273716], Loss: 0.0219, Train time: 58.29\n",
      "Epoch [1/1], Step [45300/273716], Loss: 0.0736, Train time: 58.37\n",
      "Epoch [1/1], Step [45400/273716], Loss: 0.0004, Train time: 58.49\n",
      "Epoch [1/1], Step [45500/273716], Loss: 0.0037, Train time: 58.65\n",
      "Epoch [1/1], Step [45600/273716], Loss: 0.0003, Train time: 58.82\n",
      "Epoch [1/1], Step [45700/273716], Loss: 0.0001, Train time: 58.92\n",
      "Epoch [1/1], Step [45800/273716], Loss: 0.0157, Train time: 59.10\n",
      "Epoch [1/1], Step [45900/273716], Loss: 0.0008, Train time: 59.20\n",
      "Epoch [1/1], Step [46000/273716], Loss: 0.0001, Train time: 59.32\n",
      "Epoch [1/1], Step [46100/273716], Loss: 0.0026, Train time: 59.42\n",
      "Epoch [1/1], Step [46200/273716], Loss: 0.0080, Train time: 59.56\n",
      "Epoch [1/1], Step [46300/273716], Loss: 0.0023, Train time: 59.71\n",
      "Epoch [1/1], Step [46400/273716], Loss: 0.0003, Train time: 59.84\n",
      "Epoch [1/1], Step [46500/273716], Loss: 0.0046, Train time: 59.90\n",
      "Epoch [1/1], Step [46600/273716], Loss: 0.0235, Train time: 60.05\n",
      "Epoch [1/1], Step [46700/273716], Loss: 0.2310, Train time: 60.15\n",
      "Epoch [1/1], Step [46800/273716], Loss: 0.0008, Train time: 60.37\n",
      "Epoch [1/1], Step [46900/273716], Loss: 0.0012, Train time: 60.46\n",
      "Epoch [1/1], Step [47000/273716], Loss: 0.0000, Train time: 60.59\n",
      "Epoch [1/1], Step [47100/273716], Loss: 0.0024, Train time: 60.66\n",
      "Epoch [1/1], Step [47200/273716], Loss: 0.0044, Train time: 60.86\n",
      "Epoch [1/1], Step [47300/273716], Loss: 0.0010, Train time: 61.05\n",
      "Epoch [1/1], Step [47400/273716], Loss: 0.0060, Train time: 61.17\n",
      "Epoch [1/1], Step [47500/273716], Loss: 0.1189, Train time: 61.26\n",
      "Epoch [1/1], Step [47600/273716], Loss: 0.0000, Train time: 61.54\n",
      "Epoch [1/1], Step [47700/273716], Loss: 0.1184, Train time: 61.67\n",
      "Epoch [1/1], Step [47800/273716], Loss: 0.0000, Train time: 61.78\n",
      "Epoch [1/1], Step [47900/273716], Loss: 0.0170, Train time: 61.90\n",
      "Epoch [1/1], Step [48000/273716], Loss: 0.0001, Train time: 62.12\n",
      "Epoch [1/1], Step [48100/273716], Loss: 0.0009, Train time: 62.30\n",
      "Epoch [1/1], Step [48200/273716], Loss: 0.0121, Train time: 62.41\n",
      "Epoch [1/1], Step [48300/273716], Loss: 0.0033, Train time: 62.48\n",
      "Epoch [1/1], Step [48400/273716], Loss: 0.0000, Train time: 62.68\n",
      "Epoch [1/1], Step [48500/273716], Loss: 0.0004, Train time: 62.77\n",
      "Epoch [1/1], Step [48600/273716], Loss: 0.0024, Train time: 62.88\n",
      "Epoch [1/1], Step [48700/273716], Loss: 0.0020, Train time: 62.96\n",
      "Epoch [1/1], Step [48800/273716], Loss: 0.0006, Train time: 63.28\n",
      "Epoch [1/1], Step [48900/273716], Loss: 0.0004, Train time: 63.39\n",
      "Epoch [1/1], Step [49000/273716], Loss: 0.0204, Train time: 63.43\n",
      "Epoch [1/1], Step [49100/273716], Loss: 0.0011, Train time: 63.60\n",
      "Epoch [1/1], Step [49200/273716], Loss: 0.0001, Train time: 63.77\n",
      "Epoch [1/1], Step [49300/273716], Loss: 0.0018, Train time: 63.87\n",
      "Epoch [1/1], Step [49400/273716], Loss: 1.1053, Train time: 63.96\n",
      "Epoch [1/1], Step [49500/273716], Loss: 0.0000, Train time: 64.18\n",
      "Epoch [1/1], Step [49600/273716], Loss: 0.0164, Train time: 64.30\n",
      "Epoch [1/1], Step [49700/273716], Loss: 0.0385, Train time: 64.39\n",
      "Epoch [1/1], Step [49800/273716], Loss: 0.0004, Train time: 64.53\n",
      "Epoch [1/1], Step [49900/273716], Loss: 0.0006, Train time: 64.70\n",
      "Epoch [1/1], Step [50000/273716], Loss: 0.0237, Train time: 64.75\n",
      "Epoch [1/1], Step [50100/273716], Loss: 0.0000, Train time: 64.92\n",
      "Epoch [1/1], Step [50200/273716], Loss: 0.0001, Train time: 65.12\n",
      "Epoch [1/1], Step [50300/273716], Loss: 0.0006, Train time: 65.20\n",
      "Epoch [1/1], Step [50400/273716], Loss: 0.0001, Train time: 65.26\n",
      "Epoch [1/1], Step [50500/273716], Loss: 0.0001, Train time: 65.42\n",
      "Epoch [1/1], Step [50600/273716], Loss: 1.1356, Train time: 65.56\n",
      "Epoch [1/1], Step [50700/273716], Loss: 0.0003, Train time: 65.77\n",
      "Epoch [1/1], Step [50800/273716], Loss: 0.0000, Train time: 65.83\n",
      "Epoch [1/1], Step [50900/273716], Loss: 0.0000, Train time: 66.05\n",
      "Epoch [1/1], Step [51000/273716], Loss: 0.0002, Train time: 66.21\n",
      "Epoch [1/1], Step [51100/273716], Loss: 0.0200, Train time: 66.29\n",
      "Epoch [1/1], Step [51200/273716], Loss: 0.2230, Train time: 66.45\n",
      "Epoch [1/1], Step [51300/273716], Loss: 0.8903, Train time: 66.53\n",
      "Epoch [1/1], Step [51400/273716], Loss: 0.0262, Train time: 66.59\n",
      "Epoch [1/1], Step [51500/273716], Loss: 0.0004, Train time: 66.82\n",
      "Epoch [1/1], Step [51600/273716], Loss: 0.0002, Train time: 66.96\n",
      "Epoch [1/1], Step [51700/273716], Loss: 0.0004, Train time: 67.07\n",
      "Epoch [1/1], Step [51800/273716], Loss: 0.0043, Train time: 67.14\n",
      "Epoch [1/1], Step [51900/273716], Loss: 0.0002, Train time: 67.21\n",
      "Epoch [1/1], Step [52000/273716], Loss: 0.0001, Train time: 67.43\n",
      "Epoch [1/1], Step [52100/273716], Loss: 0.0021, Train time: 67.60\n",
      "Epoch [1/1], Step [52200/273716], Loss: 0.0004, Train time: 67.70\n",
      "Epoch [1/1], Step [52300/273716], Loss: 0.0001, Train time: 67.85\n",
      "Epoch [1/1], Step [52400/273716], Loss: 0.0001, Train time: 68.02\n",
      "Epoch [1/1], Step [52500/273716], Loss: 0.0000, Train time: 68.14\n",
      "Epoch [1/1], Step [52600/273716], Loss: 0.0026, Train time: 68.21\n",
      "Epoch [1/1], Step [52700/273716], Loss: 0.0007, Train time: 68.38\n",
      "Epoch [1/1], Step [52800/273716], Loss: 0.0192, Train time: 68.45\n",
      "Epoch [1/1], Step [52900/273716], Loss: 0.0048, Train time: 68.52\n",
      "Epoch [1/1], Step [53000/273716], Loss: 0.0063, Train time: 68.74\n",
      "Epoch [1/1], Step [53100/273716], Loss: 0.0057, Train time: 68.89\n",
      "Epoch [1/1], Step [53200/273716], Loss: 0.0002, Train time: 68.97\n",
      "Epoch [1/1], Step [53300/273716], Loss: 0.0002, Train time: 69.23\n",
      "Epoch [1/1], Step [53400/273716], Loss: 0.0056, Train time: 69.30\n",
      "Epoch [1/1], Step [53500/273716], Loss: 0.0040, Train time: 69.40\n",
      "Epoch [1/1], Step [53600/273716], Loss: 0.1498, Train time: 69.57\n",
      "Epoch [1/1], Step [53700/273716], Loss: 0.0460, Train time: 69.75\n",
      "Epoch [1/1], Step [53800/273716], Loss: 0.0003, Train time: 69.82\n",
      "Epoch [1/1], Step [53900/273716], Loss: 0.0009, Train time: 69.99\n",
      "Epoch [1/1], Step [54000/273716], Loss: 0.0001, Train time: 70.19\n",
      "Epoch [1/1], Step [54100/273716], Loss: 0.0022, Train time: 70.28\n",
      "Epoch [1/1], Step [54200/273716], Loss: 0.0244, Train time: 70.41\n",
      "Epoch [1/1], Step [54300/273716], Loss: 0.0030, Train time: 70.60\n",
      "Epoch [1/1], Step [54400/273716], Loss: 0.3646, Train time: 70.65\n",
      "Epoch [1/1], Step [54500/273716], Loss: 0.0002, Train time: 70.81\n",
      "Epoch [1/1], Step [54600/273716], Loss: 0.0001, Train time: 70.92\n",
      "Epoch [1/1], Step [54700/273716], Loss: 0.0040, Train time: 71.04\n",
      "Epoch [1/1], Step [54800/273716], Loss: 0.0011, Train time: 71.19\n",
      "Epoch [1/1], Step [54900/273716], Loss: 0.0001, Train time: 71.35\n",
      "Epoch [1/1], Step [55000/273716], Loss: 0.0005, Train time: 71.57\n",
      "Epoch [1/1], Step [55100/273716], Loss: 0.0001, Train time: 71.77\n",
      "Epoch [1/1], Step [55200/273716], Loss: 0.0731, Train time: 71.82\n",
      "Epoch [1/1], Step [55300/273716], Loss: 0.0308, Train time: 72.01\n",
      "Epoch [1/1], Step [55400/273716], Loss: 0.0002, Train time: 72.14\n",
      "Epoch [1/1], Step [55500/273716], Loss: 0.0000, Train time: 72.24\n",
      "Epoch [1/1], Step [55600/273716], Loss: 0.1552, Train time: 72.43\n",
      "Epoch [1/1], Step [55700/273716], Loss: 0.0117, Train time: 72.48\n",
      "Epoch [1/1], Step [55800/273716], Loss: 0.0243, Train time: 72.64\n",
      "Epoch [1/1], Step [55900/273716], Loss: 0.0002, Train time: 72.81\n",
      "Epoch [1/1], Step [56000/273716], Loss: 0.0006, Train time: 72.96\n",
      "Epoch [1/1], Step [56100/273716], Loss: 0.0030, Train time: 73.03\n",
      "Epoch [1/1], Step [56200/273716], Loss: 0.0015, Train time: 73.11\n",
      "Epoch [1/1], Step [56300/273716], Loss: 0.6820, Train time: 73.39\n",
      "Epoch [1/1], Step [56400/273716], Loss: 0.0001, Train time: 73.57\n",
      "Epoch [1/1], Step [56500/273716], Loss: 0.0001, Train time: 73.73\n",
      "Epoch [1/1], Step [56600/273716], Loss: 0.0000, Train time: 73.81\n",
      "Epoch [1/1], Step [56700/273716], Loss: 0.0023, Train time: 73.96\n",
      "Epoch [1/1], Step [56800/273716], Loss: 0.0002, Train time: 74.11\n",
      "Epoch [1/1], Step [56900/273716], Loss: 0.0000, Train time: 74.18\n",
      "Epoch [1/1], Step [57000/273716], Loss: 0.0031, Train time: 74.35\n",
      "Epoch [1/1], Step [57100/273716], Loss: 0.0010, Train time: 74.43\n",
      "Epoch [1/1], Step [57200/273716], Loss: 0.0003, Train time: 74.54\n",
      "Epoch [1/1], Step [57300/273716], Loss: 0.0000, Train time: 74.66\n",
      "Epoch [1/1], Step [57400/273716], Loss: 0.0100, Train time: 74.72\n",
      "Epoch [1/1], Step [57500/273716], Loss: 0.0012, Train time: 74.92\n",
      "Epoch [1/1], Step [57600/273716], Loss: 0.0083, Train time: 75.08\n",
      "Epoch [1/1], Step [57700/273716], Loss: 0.0021, Train time: 75.25\n",
      "Epoch [1/1], Step [57800/273716], Loss: 0.0021, Train time: 75.33\n",
      "Epoch [1/1], Step [57900/273716], Loss: 0.0207, Train time: 75.43\n",
      "Epoch [1/1], Step [58000/273716], Loss: 0.0009, Train time: 75.66\n",
      "Epoch [1/1], Step [58100/273716], Loss: 0.0003, Train time: 75.75\n",
      "Epoch [1/1], Step [58200/273716], Loss: 0.0002, Train time: 75.84\n",
      "Epoch [1/1], Step [58300/273716], Loss: 0.0000, Train time: 75.92\n",
      "Epoch [1/1], Step [58400/273716], Loss: 0.0100, Train time: 75.96\n",
      "Epoch [1/1], Step [58500/273716], Loss: 0.0020, Train time: 76.22\n",
      "Epoch [1/1], Step [58600/273716], Loss: 0.0006, Train time: 76.26\n",
      "Epoch [1/1], Step [58700/273716], Loss: 0.0001, Train time: 76.34\n",
      "Epoch [1/1], Step [58800/273716], Loss: 0.0004, Train time: 76.57\n",
      "Epoch [1/1], Step [58900/273716], Loss: 0.0046, Train time: 76.67\n",
      "Epoch [1/1], Step [59000/273716], Loss: 0.0004, Train time: 76.73\n",
      "Epoch [1/1], Step [59100/273716], Loss: 0.5288, Train time: 76.95\n",
      "Epoch [1/1], Step [59200/273716], Loss: 0.8877, Train time: 77.11\n",
      "Epoch [1/1], Step [59300/273716], Loss: 0.0003, Train time: 77.20\n",
      "Epoch [1/1], Step [59400/273716], Loss: 0.0069, Train time: 77.37\n",
      "Epoch [1/1], Step [59500/273716], Loss: 0.0030, Train time: 77.47\n",
      "Epoch [1/1], Step [59600/273716], Loss: 0.0004, Train time: 77.54\n",
      "Epoch [1/1], Step [59700/273716], Loss: 0.0142, Train time: 77.74\n",
      "Epoch [1/1], Step [59800/273716], Loss: 0.0006, Train time: 77.85\n",
      "Epoch [1/1], Step [59900/273716], Loss: 0.0001, Train time: 77.97\n",
      "Epoch [1/1], Step [60000/273716], Loss: 0.0015, Train time: 78.04\n",
      "Epoch [1/1], Step [60100/273716], Loss: 0.0001, Train time: 78.29\n",
      "Epoch [1/1], Step [60200/273716], Loss: 0.0036, Train time: 78.44\n",
      "Epoch [1/1], Step [60300/273716], Loss: 0.0187, Train time: 78.52\n",
      "Epoch [1/1], Step [60400/273716], Loss: 0.0031, Train time: 78.69\n",
      "Epoch [1/1], Step [60500/273716], Loss: 0.4291, Train time: 78.83\n",
      "Epoch [1/1], Step [60600/273716], Loss: 0.0066, Train time: 78.92\n",
      "Epoch [1/1], Step [60700/273716], Loss: 0.0016, Train time: 79.05\n",
      "Epoch [1/1], Step [60800/273716], Loss: 0.0075, Train time: 79.23\n",
      "Epoch [1/1], Step [60900/273716], Loss: 0.0025, Train time: 79.32\n",
      "Epoch [1/1], Step [61000/273716], Loss: 0.0057, Train time: 79.45\n",
      "Epoch [1/1], Step [61100/273716], Loss: 0.0343, Train time: 79.65\n",
      "Epoch [1/1], Step [61200/273716], Loss: 0.0110, Train time: 79.84\n",
      "Epoch [1/1], Step [61300/273716], Loss: 0.0004, Train time: 79.90\n",
      "Epoch [1/1], Step [61400/273716], Loss: 0.0002, Train time: 80.16\n",
      "Epoch [1/1], Step [61500/273716], Loss: 0.0053, Train time: 80.36\n",
      "Epoch [1/1], Step [61600/273716], Loss: 0.0013, Train time: 80.49\n",
      "Epoch [1/1], Step [61700/273716], Loss: 0.0020, Train time: 80.64\n",
      "Epoch [1/1], Step [61800/273716], Loss: 0.0000, Train time: 80.76\n",
      "Epoch [1/1], Step [61900/273716], Loss: 0.0054, Train time: 80.88\n",
      "Epoch [1/1], Step [62000/273716], Loss: 0.0422, Train time: 80.91\n",
      "Epoch [1/1], Step [62100/273716], Loss: 0.0072, Train time: 81.06\n",
      "Epoch [1/1], Step [62200/273716], Loss: 0.0008, Train time: 81.34\n",
      "Epoch [1/1], Step [62300/273716], Loss: 0.0051, Train time: 81.51\n",
      "Epoch [1/1], Step [62400/273716], Loss: 0.0051, Train time: 81.65\n",
      "Epoch [1/1], Step [62500/273716], Loss: 0.0043, Train time: 81.92\n",
      "Epoch [1/1], Step [62600/273716], Loss: 0.0394, Train time: 82.08\n",
      "Epoch [1/1], Step [62700/273716], Loss: 0.0442, Train time: 82.11\n",
      "Epoch [1/1], Step [62800/273716], Loss: 0.0675, Train time: 82.31\n",
      "Epoch [1/1], Step [62900/273716], Loss: 0.0000, Train time: 82.40\n",
      "Epoch [1/1], Step [63000/273716], Loss: 0.0047, Train time: 82.51\n",
      "Epoch [1/1], Step [63100/273716], Loss: 0.0018, Train time: 82.77\n",
      "Epoch [1/1], Step [63200/273716], Loss: 1.0594, Train time: 82.86\n",
      "Epoch [1/1], Step [63300/273716], Loss: 0.0428, Train time: 82.92\n",
      "Epoch [1/1], Step [63400/273716], Loss: 0.0065, Train time: 83.11\n",
      "Epoch [1/1], Step [63500/273716], Loss: 0.0006, Train time: 83.18\n",
      "Epoch [1/1], Step [63600/273716], Loss: 0.0476, Train time: 83.34\n",
      "Epoch [1/1], Step [63700/273716], Loss: 0.0038, Train time: 83.58\n",
      "Epoch [1/1], Step [63800/273716], Loss: 0.0002, Train time: 83.71\n",
      "Epoch [1/1], Step [63900/273716], Loss: 0.0065, Train time: 83.93\n",
      "Epoch [1/1], Step [64000/273716], Loss: 0.0050, Train time: 84.08\n",
      "Epoch [1/1], Step [64100/273716], Loss: 0.0209, Train time: 84.16\n",
      "Epoch [1/1], Step [64200/273716], Loss: 0.0000, Train time: 84.40\n",
      "Epoch [1/1], Step [64300/273716], Loss: 0.0313, Train time: 84.49\n",
      "Epoch [1/1], Step [64400/273716], Loss: 0.0006, Train time: 84.54\n",
      "Epoch [1/1], Step [64500/273716], Loss: 0.0000, Train time: 84.75\n",
      "Epoch [1/1], Step [64600/273716], Loss: 0.0055, Train time: 84.96\n",
      "Epoch [1/1], Step [64700/273716], Loss: 0.0000, Train time: 85.00\n",
      "Epoch [1/1], Step [64800/273716], Loss: 0.0028, Train time: 85.15\n",
      "Epoch [1/1], Step [64900/273716], Loss: 0.0001, Train time: 85.19\n",
      "Epoch [1/1], Step [65000/273716], Loss: 0.0295, Train time: 85.22\n",
      "Epoch [1/1], Step [65100/273716], Loss: 0.0000, Train time: 85.35\n",
      "Epoch [1/1], Step [65200/273716], Loss: 0.0018, Train time: 85.38\n",
      "Epoch [1/1], Step [65300/273716], Loss: 0.0161, Train time: 85.44\n",
      "Epoch [1/1], Step [65400/273716], Loss: 0.0014, Train time: 86.17\n",
      "Epoch [1/1], Step [65500/273716], Loss: 0.0011, Train time: 86.22\n",
      "Epoch [1/1], Step [65600/273716], Loss: 0.0005, Train time: 86.28\n",
      "Epoch [1/1], Step [65700/273716], Loss: 0.0039, Train time: 86.42\n",
      "Epoch [1/1], Step [65800/273716], Loss: 0.0002, Train time: 86.46\n",
      "Epoch [1/1], Step [65900/273716], Loss: 0.0007, Train time: 86.54\n",
      "Epoch [1/1], Step [66000/273716], Loss: 0.0005, Train time: 86.66\n",
      "Epoch [1/1], Step [66100/273716], Loss: 0.0004, Train time: 86.88\n",
      "Epoch [1/1], Step [66200/273716], Loss: 0.0000, Train time: 86.98\n",
      "Epoch [1/1], Step [66300/273716], Loss: 0.0005, Train time: 87.06\n",
      "Epoch [1/1], Step [66400/273716], Loss: 0.0005, Train time: 87.23\n",
      "Epoch [1/1], Step [66500/273716], Loss: 0.0000, Train time: 87.42\n",
      "Epoch [1/1], Step [66600/273716], Loss: 0.0008, Train time: 87.53\n",
      "Epoch [1/1], Step [66700/273716], Loss: 0.0007, Train time: 87.61\n",
      "Epoch [1/1], Step [66800/273716], Loss: 0.0000, Train time: 87.77\n",
      "Epoch [1/1], Step [66900/273716], Loss: 0.0007, Train time: 87.91\n",
      "Epoch [1/1], Step [67000/273716], Loss: 3.4604, Train time: 88.09\n",
      "Epoch [1/1], Step [67100/273716], Loss: 0.0000, Train time: 88.14\n",
      "Epoch [1/1], Step [67200/273716], Loss: 0.0102, Train time: 88.42\n",
      "Epoch [1/1], Step [67300/273716], Loss: 0.0029, Train time: 88.52\n",
      "Epoch [1/1], Step [67400/273716], Loss: 0.0009, Train time: 88.61\n",
      "Epoch [1/1], Step [67500/273716], Loss: 0.0036, Train time: 88.71\n",
      "Epoch [1/1], Step [67600/273716], Loss: 0.0001, Train time: 88.79\n",
      "Epoch [1/1], Step [67700/273716], Loss: 0.0011, Train time: 89.04\n",
      "Epoch [1/1], Step [67800/273716], Loss: 0.0005, Train time: 89.22\n",
      "Epoch [1/1], Step [67900/273716], Loss: 0.0002, Train time: 89.29\n",
      "Epoch [1/1], Step [68000/273716], Loss: 0.0001, Train time: 89.39\n",
      "Epoch [1/1], Step [68100/273716], Loss: 0.0027, Train time: 89.62\n",
      "Epoch [1/1], Step [68200/273716], Loss: 0.0103, Train time: 89.81\n",
      "Epoch [1/1], Step [68300/273716], Loss: 0.0000, Train time: 89.88\n",
      "Epoch [1/1], Step [68400/273716], Loss: 0.0127, Train time: 89.96\n",
      "Epoch [1/1], Step [68500/273716], Loss: 0.0014, Train time: 90.06\n",
      "Epoch [1/1], Step [68600/273716], Loss: 0.0023, Train time: 90.30\n",
      "Epoch [1/1], Step [68700/273716], Loss: 0.0051, Train time: 90.37\n",
      "Epoch [1/1], Step [68800/273716], Loss: 0.0028, Train time: 90.45\n",
      "Epoch [1/1], Step [68900/273716], Loss: 0.0053, Train time: 90.56\n",
      "Epoch [1/1], Step [69000/273716], Loss: 0.8023, Train time: 90.67\n",
      "Epoch [1/1], Step [69100/273716], Loss: 0.0003, Train time: 90.87\n",
      "Epoch [1/1], Step [69200/273716], Loss: 0.1574, Train time: 90.94\n",
      "Epoch [1/1], Step [69300/273716], Loss: 0.0319, Train time: 91.26\n",
      "Epoch [1/1], Step [69400/273716], Loss: 0.0292, Train time: 91.33\n",
      "Epoch [1/1], Step [69500/273716], Loss: 0.0455, Train time: 91.41\n",
      "Epoch [1/1], Step [69600/273716], Loss: 0.0000, Train time: 91.60\n",
      "Epoch [1/1], Step [69700/273716], Loss: 0.0129, Train time: 91.76\n",
      "Epoch [1/1], Step [69800/273716], Loss: 0.0057, Train time: 91.88\n",
      "Epoch [1/1], Step [69900/273716], Loss: 0.0240, Train time: 91.95\n",
      "Epoch [1/1], Step [70000/273716], Loss: 0.0000, Train time: 92.12\n",
      "Epoch [1/1], Step [70100/273716], Loss: 0.0272, Train time: 92.25\n",
      "Epoch [1/1], Step [70200/273716], Loss: 0.0061, Train time: 92.30\n",
      "Epoch [1/1], Step [70300/273716], Loss: 0.0152, Train time: 92.47\n",
      "Epoch [1/1], Step [70400/273716], Loss: 0.0102, Train time: 92.55\n",
      "Epoch [1/1], Step [70500/273716], Loss: 0.0023, Train time: 92.83\n",
      "Epoch [1/1], Step [70600/273716], Loss: 0.0000, Train time: 92.89\n",
      "Epoch [1/1], Step [70700/273716], Loss: 0.0317, Train time: 92.99\n",
      "Epoch [1/1], Step [70800/273716], Loss: 0.0015, Train time: 93.23\n",
      "Epoch [1/1], Step [70900/273716], Loss: 0.0015, Train time: 93.30\n",
      "Epoch [1/1], Step [71000/273716], Loss: 0.0005, Train time: 93.43\n",
      "Epoch [1/1], Step [71100/273716], Loss: 0.0023, Train time: 93.62\n",
      "Epoch [1/1], Step [71200/273716], Loss: 0.0008, Train time: 93.78\n",
      "Epoch [1/1], Step [71300/273716], Loss: 0.0257, Train time: 93.88\n",
      "Epoch [1/1], Step [71400/273716], Loss: 0.1602, Train time: 93.95\n",
      "Epoch [1/1], Step [71500/273716], Loss: 0.0098, Train time: 94.08\n",
      "Epoch [1/1], Step [71600/273716], Loss: 0.0054, Train time: 94.37\n",
      "Epoch [1/1], Step [71700/273716], Loss: 0.0004, Train time: 94.50\n",
      "Epoch [1/1], Step [71800/273716], Loss: 0.0056, Train time: 94.55\n",
      "Epoch [1/1], Step [71900/273716], Loss: 0.0000, Train time: 94.64\n",
      "Epoch [1/1], Step [72000/273716], Loss: 0.0000, Train time: 94.74\n",
      "Epoch [1/1], Step [72100/273716], Loss: 0.0004, Train time: 95.07\n",
      "Epoch [1/1], Step [72200/273716], Loss: 0.0026, Train time: 95.16\n",
      "Epoch [1/1], Step [72300/273716], Loss: 0.0779, Train time: 95.25\n",
      "Epoch [1/1], Step [72400/273716], Loss: 0.0011, Train time: 95.30\n",
      "Epoch [1/1], Step [72500/273716], Loss: 0.0001, Train time: 95.36\n",
      "Epoch [1/1], Step [72600/273716], Loss: 0.0000, Train time: 95.69\n",
      "Epoch [1/1], Step [72700/273716], Loss: 0.0000, Train time: 95.81\n",
      "Epoch [1/1], Step [72800/273716], Loss: 0.0149, Train time: 96.06\n",
      "Epoch [1/1], Step [72900/273716], Loss: 0.0001, Train time: 96.11\n",
      "Epoch [1/1], Step [73000/273716], Loss: 0.0025, Train time: 96.18\n",
      "Epoch [1/1], Step [73100/273716], Loss: 0.0000, Train time: 96.40\n",
      "Epoch [1/1], Step [73200/273716], Loss: 0.1383, Train time: 96.45\n",
      "Epoch [1/1], Step [73300/273716], Loss: 0.0000, Train time: 96.59\n",
      "Epoch [1/1], Step [73400/273716], Loss: 0.0003, Train time: 96.81\n",
      "Epoch [1/1], Step [73500/273716], Loss: 0.0003, Train time: 96.89\n",
      "Epoch [1/1], Step [73600/273716], Loss: 0.0145, Train time: 97.09\n",
      "Epoch [1/1], Step [73700/273716], Loss: 0.0000, Train time: 97.15\n",
      "Epoch [1/1], Step [73800/273716], Loss: 0.0005, Train time: 97.30\n",
      "Epoch [1/1], Step [73900/273716], Loss: 0.0000, Train time: 97.41\n",
      "Epoch [1/1], Step [74000/273716], Loss: 0.0004, Train time: 97.64\n",
      "Epoch [1/1], Step [74100/273716], Loss: 0.0030, Train time: 97.73\n",
      "Epoch [1/1], Step [74200/273716], Loss: 0.0117, Train time: 97.83\n",
      "Epoch [1/1], Step [74300/273716], Loss: 0.0003, Train time: 98.00\n",
      "Epoch [1/1], Step [74400/273716], Loss: 0.0002, Train time: 98.15\n",
      "Epoch [1/1], Step [74500/273716], Loss: 0.0000, Train time: 98.22\n",
      "Epoch [1/1], Step [74600/273716], Loss: 0.0076, Train time: 98.32\n",
      "Epoch [1/1], Step [74700/273716], Loss: 0.0000, Train time: 98.48\n",
      "Epoch [1/1], Step [74800/273716], Loss: 0.0003, Train time: 98.67\n",
      "Epoch [1/1], Step [74900/273716], Loss: 0.0006, Train time: 98.81\n",
      "Epoch [1/1], Step [75000/273716], Loss: 0.0053, Train time: 98.92\n",
      "Epoch [1/1], Step [75100/273716], Loss: 0.0000, Train time: 99.12\n",
      "Epoch [1/1], Step [75200/273716], Loss: 0.0013, Train time: 99.25\n",
      "Epoch [1/1], Step [75300/273716], Loss: 0.0027, Train time: 99.31\n",
      "Epoch [1/1], Step [75400/273716], Loss: 0.0001, Train time: 99.40\n",
      "Epoch [1/1], Step [75500/273716], Loss: 0.0022, Train time: 99.66\n",
      "Epoch [1/1], Step [75600/273716], Loss: 0.0003, Train time: 99.74\n",
      "Epoch [1/1], Step [75700/273716], Loss: 0.0494, Train time: 99.83\n",
      "Epoch [1/1], Step [75800/273716], Loss: 0.0002, Train time: 99.92\n",
      "Epoch [1/1], Step [75900/273716], Loss: 0.0075, Train time: 100.13\n",
      "Epoch [1/1], Step [76000/273716], Loss: 0.0038, Train time: 100.17\n",
      "Epoch [1/1], Step [76100/273716], Loss: 0.0000, Train time: 100.23\n",
      "Epoch [1/1], Step [76200/273716], Loss: 4.7092, Train time: 100.46\n",
      "Epoch [1/1], Step [76300/273716], Loss: 0.0379, Train time: 100.62\n",
      "Epoch [1/1], Step [76400/273716], Loss: 0.0194, Train time: 100.72\n",
      "Epoch [1/1], Step [76500/273716], Loss: 0.1365, Train time: 100.83\n",
      "Epoch [1/1], Step [76600/273716], Loss: 0.0014, Train time: 101.17\n",
      "Epoch [1/1], Step [76700/273716], Loss: 0.0001, Train time: 101.27\n",
      "Epoch [1/1], Step [76800/273716], Loss: 0.0002, Train time: 101.36\n",
      "Epoch [1/1], Step [76900/273716], Loss: 0.0080, Train time: 101.70\n",
      "Epoch [1/1], Step [77000/273716], Loss: 0.0174, Train time: 101.90\n",
      "Epoch [1/1], Step [77100/273716], Loss: 0.0004, Train time: 102.01\n",
      "Epoch [1/1], Step [77200/273716], Loss: 0.0021, Train time: 102.12\n",
      "Epoch [1/1], Step [77300/273716], Loss: 0.0001, Train time: 102.19\n",
      "Epoch [1/1], Step [77400/273716], Loss: 0.0016, Train time: 102.40\n",
      "Epoch [1/1], Step [77500/273716], Loss: 0.0049, Train time: 102.46\n",
      "Epoch [1/1], Step [77600/273716], Loss: 0.0000, Train time: 102.51\n",
      "Epoch [1/1], Step [77700/273716], Loss: 0.0001, Train time: 102.70\n",
      "Epoch [1/1], Step [77800/273716], Loss: 0.0004, Train time: 102.84\n",
      "Epoch [1/1], Step [77900/273716], Loss: 0.0000, Train time: 103.06\n",
      "Epoch [1/1], Step [78000/273716], Loss: 0.0094, Train time: 103.23\n",
      "Epoch [1/1], Step [78100/273716], Loss: 0.0001, Train time: 103.27\n",
      "Epoch [1/1], Step [78200/273716], Loss: 0.0024, Train time: 103.37\n",
      "Epoch [1/1], Step [78300/273716], Loss: 0.0000, Train time: 103.65\n",
      "Epoch [1/1], Step [78400/273716], Loss: 0.0003, Train time: 103.69\n",
      "Epoch [1/1], Step [78500/273716], Loss: 0.0318, Train time: 103.79\n",
      "Epoch [1/1], Step [78600/273716], Loss: 0.0001, Train time: 103.91\n",
      "Epoch [1/1], Step [78700/273716], Loss: 0.0000, Train time: 103.99\n",
      "Epoch [1/1], Step [78800/273716], Loss: 0.0000, Train time: 104.17\n",
      "Epoch [1/1], Step [78900/273716], Loss: 0.0042, Train time: 104.23\n",
      "Epoch [1/1], Step [79000/273716], Loss: 0.0040, Train time: 104.53\n",
      "Epoch [1/1], Step [79100/273716], Loss: 0.0000, Train time: 104.60\n",
      "Epoch [1/1], Step [79200/273716], Loss: 0.0000, Train time: 104.66\n",
      "Epoch [1/1], Step [79300/273716], Loss: 0.0026, Train time: 104.94\n",
      "Epoch [1/1], Step [79400/273716], Loss: 0.0014, Train time: 104.97\n",
      "Epoch [1/1], Step [79500/273716], Loss: 0.0015, Train time: 105.01\n",
      "Epoch [1/1], Step [79600/273716], Loss: 0.0000, Train time: 105.17\n",
      "Epoch [1/1], Step [79700/273716], Loss: 0.0003, Train time: 105.40\n",
      "Epoch [1/1], Step [79800/273716], Loss: 0.0002, Train time: 105.56\n",
      "Epoch [1/1], Step [79900/273716], Loss: 0.0146, Train time: 105.63\n",
      "Epoch [1/1], Step [80000/273716], Loss: 0.0059, Train time: 105.66\n",
      "Epoch [1/1], Step [80100/273716], Loss: 0.0003, Train time: 105.90\n",
      "Epoch [1/1], Step [80200/273716], Loss: 0.0209, Train time: 106.13\n",
      "Epoch [1/1], Step [80300/273716], Loss: 0.0053, Train time: 106.26\n",
      "Epoch [1/1], Step [80400/273716], Loss: 0.0006, Train time: 106.36\n",
      "Epoch [1/1], Step [80500/273716], Loss: 2.9174, Train time: 106.70\n",
      "Epoch [1/1], Step [80600/273716], Loss: 0.3231, Train time: 106.80\n",
      "Epoch [1/1], Step [80700/273716], Loss: 0.0014, Train time: 106.85\n",
      "Epoch [1/1], Step [80800/273716], Loss: 0.0097, Train time: 106.91\n",
      "Epoch [1/1], Step [80900/273716], Loss: 0.0005, Train time: 107.13\n",
      "Epoch [1/1], Step [81000/273716], Loss: 0.0001, Train time: 107.19\n",
      "Epoch [1/1], Step [81100/273716], Loss: 0.4383, Train time: 107.25\n",
      "Epoch [1/1], Step [81200/273716], Loss: 0.0009, Train time: 107.34\n",
      "Epoch [1/1], Step [81300/273716], Loss: 0.0000, Train time: 107.56\n",
      "Epoch [1/1], Step [81400/273716], Loss: 0.0004, Train time: 107.77\n",
      "Epoch [1/1], Step [81500/273716], Loss: 0.0253, Train time: 107.86\n",
      "Epoch [1/1], Step [81600/273716], Loss: 0.0018, Train time: 107.89\n",
      "Epoch [1/1], Step [81700/273716], Loss: 0.0040, Train time: 108.15\n",
      "Epoch [1/1], Step [81800/273716], Loss: 0.0001, Train time: 108.34\n",
      "Epoch [1/1], Step [81900/273716], Loss: 0.0006, Train time: 108.46\n",
      "Epoch [1/1], Step [82000/273716], Loss: 0.0308, Train time: 108.53\n",
      "Epoch [1/1], Step [82100/273716], Loss: 0.0023, Train time: 108.61\n",
      "Epoch [1/1], Step [82200/273716], Loss: 0.4680, Train time: 108.85\n",
      "Epoch [1/1], Step [82300/273716], Loss: 0.0338, Train time: 108.90\n",
      "Epoch [1/1], Step [82400/273716], Loss: 0.0001, Train time: 109.00\n",
      "Epoch [1/1], Step [82500/273716], Loss: 0.0004, Train time: 109.06\n",
      "Epoch [1/1], Step [82600/273716], Loss: 0.2722, Train time: 109.25\n",
      "Epoch [1/1], Step [82700/273716], Loss: 0.0003, Train time: 109.35\n",
      "Epoch [1/1], Step [82800/273716], Loss: 0.1966, Train time: 109.68\n",
      "Epoch [1/1], Step [82900/273716], Loss: 0.0003, Train time: 109.75\n",
      "Epoch [1/1], Step [83000/273716], Loss: 0.0019, Train time: 109.81\n",
      "Epoch [1/1], Step [83100/273716], Loss: 0.0016, Train time: 109.90\n",
      "Epoch [1/1], Step [83200/273716], Loss: 0.0000, Train time: 110.02\n",
      "Epoch [1/1], Step [83300/273716], Loss: 0.0004, Train time: 110.09\n",
      "Epoch [1/1], Step [83400/273716], Loss: 0.0024, Train time: 110.34\n",
      "Epoch [1/1], Step [83500/273716], Loss: 0.0022, Train time: 110.41\n",
      "Epoch [1/1], Step [83600/273716], Loss: 0.0409, Train time: 110.44\n",
      "Epoch [1/1], Step [83700/273716], Loss: 0.0076, Train time: 110.47\n",
      "Epoch [1/1], Step [83800/273716], Loss: 0.0114, Train time: 110.67\n",
      "Epoch [1/1], Step [83900/273716], Loss: 0.0012, Train time: 110.90\n",
      "Epoch [1/1], Step [84000/273716], Loss: 0.0016, Train time: 111.15\n",
      "Epoch [1/1], Step [84100/273716], Loss: 0.0066, Train time: 111.32\n",
      "Epoch [1/1], Step [84200/273716], Loss: 0.0002, Train time: 111.42\n",
      "Epoch [1/1], Step [84300/273716], Loss: 0.0026, Train time: 111.53\n",
      "Epoch [1/1], Step [84400/273716], Loss: 0.0015, Train time: 111.65\n",
      "Epoch [1/1], Step [84500/273716], Loss: 0.0002, Train time: 111.75\n",
      "Epoch [1/1], Step [84600/273716], Loss: 0.0041, Train time: 112.00\n",
      "Epoch [1/1], Step [84700/273716], Loss: 0.0021, Train time: 112.18\n",
      "Epoch [1/1], Step [84800/273716], Loss: 0.0008, Train time: 112.24\n",
      "Epoch [1/1], Step [84900/273716], Loss: 0.0001, Train time: 112.31\n",
      "Epoch [1/1], Step [85000/273716], Loss: 0.0002, Train time: 112.44\n",
      "Epoch [1/1], Step [85100/273716], Loss: 0.0085, Train time: 112.69\n",
      "Epoch [1/1], Step [85200/273716], Loss: 0.0007, Train time: 112.88\n",
      "Epoch [1/1], Step [85300/273716], Loss: 0.0000, Train time: 113.15\n",
      "Epoch [1/1], Step [85400/273716], Loss: 0.0008, Train time: 113.26\n",
      "Epoch [1/1], Step [85500/273716], Loss: 0.0117, Train time: 113.36\n",
      "Epoch [1/1], Step [85600/273716], Loss: 10.6396, Train time: 113.48\n",
      "Epoch [1/1], Step [85700/273716], Loss: 0.0001, Train time: 113.55\n",
      "Epoch [1/1], Step [85800/273716], Loss: 0.0000, Train time: 113.64\n",
      "Epoch [1/1], Step [85900/273716], Loss: 0.0010, Train time: 113.88\n",
      "Epoch [1/1], Step [86000/273716], Loss: 0.0429, Train time: 113.99\n",
      "Epoch [1/1], Step [86100/273716], Loss: 0.0001, Train time: 114.24\n",
      "Epoch [1/1], Step [86200/273716], Loss: 0.0000, Train time: 114.29\n",
      "Epoch [1/1], Step [86300/273716], Loss: 0.0000, Train time: 114.47\n",
      "Epoch [1/1], Step [86400/273716], Loss: 0.0402, Train time: 114.60\n",
      "Epoch [1/1], Step [86500/273716], Loss: 0.0004, Train time: 114.77\n",
      "Epoch [1/1], Step [86600/273716], Loss: 0.0000, Train time: 114.82\n",
      "Epoch [1/1], Step [86700/273716], Loss: 0.0000, Train time: 115.11\n",
      "Epoch [1/1], Step [86800/273716], Loss: 0.0002, Train time: 115.19\n",
      "Epoch [1/1], Step [86900/273716], Loss: 0.0211, Train time: 115.38\n",
      "Epoch [1/1], Step [87000/273716], Loss: 1.9032, Train time: 115.48\n",
      "Epoch [1/1], Step [87100/273716], Loss: 0.0049, Train time: 115.56\n",
      "Epoch [1/1], Step [87200/273716], Loss: 0.0000, Train time: 115.61\n",
      "Epoch [1/1], Step [87300/273716], Loss: 0.0053, Train time: 115.88\n",
      "Epoch [1/1], Step [87400/273716], Loss: 0.0000, Train time: 116.03\n",
      "Epoch [1/1], Step [87500/273716], Loss: 0.0071, Train time: 116.14\n",
      "Epoch [1/1], Step [87600/273716], Loss: 0.0003, Train time: 116.34\n",
      "Epoch [1/1], Step [87700/273716], Loss: 0.0018, Train time: 116.45\n",
      "Epoch [1/1], Step [87800/273716], Loss: 0.0862, Train time: 116.64\n",
      "Epoch [1/1], Step [87900/273716], Loss: 0.1513, Train time: 116.83\n",
      "Epoch [1/1], Step [88000/273716], Loss: 0.0008, Train time: 116.89\n",
      "Epoch [1/1], Step [88100/273716], Loss: 0.4579, Train time: 117.21\n",
      "Epoch [1/1], Step [88200/273716], Loss: 0.0000, Train time: 117.37\n",
      "Epoch [1/1], Step [88300/273716], Loss: 0.0021, Train time: 117.63\n",
      "Epoch [1/1], Step [88400/273716], Loss: 0.0000, Train time: 117.70\n",
      "Epoch [1/1], Step [88500/273716], Loss: 0.0534, Train time: 117.91\n",
      "Epoch [1/1], Step [88600/273716], Loss: 0.0010, Train time: 118.07\n",
      "Epoch [1/1], Step [88700/273716], Loss: 0.0013, Train time: 118.13\n",
      "Epoch [1/1], Step [88800/273716], Loss: 0.0266, Train time: 118.39\n",
      "Epoch [1/1], Step [88900/273716], Loss: 0.0014, Train time: 118.65\n",
      "Epoch [1/1], Step [89000/273716], Loss: 0.0008, Train time: 118.84\n",
      "Epoch [1/1], Step [89100/273716], Loss: 0.0094, Train time: 118.89\n",
      "Epoch [1/1], Step [89200/273716], Loss: 0.0006, Train time: 119.02\n",
      "Epoch [1/1], Step [89300/273716], Loss: 0.0021, Train time: 119.40\n",
      "Epoch [1/1], Step [89400/273716], Loss: 0.0000, Train time: 119.49\n",
      "Epoch [1/1], Step [89500/273716], Loss: 0.0012, Train time: 119.53\n",
      "Epoch [1/1], Step [89600/273716], Loss: 0.0001, Train time: 119.74\n",
      "Epoch [1/1], Step [89700/273716], Loss: 0.4801, Train time: 119.89\n",
      "Epoch [1/1], Step [89800/273716], Loss: 0.0000, Train time: 119.95\n",
      "Epoch [1/1], Step [89900/273716], Loss: 0.0003, Train time: 120.09\n",
      "Epoch [1/1], Step [90000/273716], Loss: 0.0094, Train time: 120.35\n",
      "Epoch [1/1], Step [90100/273716], Loss: 0.0008, Train time: 120.50\n",
      "Epoch [1/1], Step [90200/273716], Loss: 0.0012, Train time: 120.53\n",
      "Epoch [1/1], Step [90300/273716], Loss: 0.0002, Train time: 120.72\n",
      "Epoch [1/1], Step [90400/273716], Loss: 0.0001, Train time: 121.03\n",
      "Epoch [1/1], Step [90500/273716], Loss: 0.0000, Train time: 121.25\n",
      "Epoch [1/1], Step [90600/273716], Loss: 0.0000, Train time: 121.38\n",
      "Epoch [1/1], Step [90700/273716], Loss: 0.0001, Train time: 121.59\n",
      "Epoch [1/1], Step [90800/273716], Loss: 0.0063, Train time: 121.74\n",
      "Epoch [1/1], Step [90900/273716], Loss: 0.0003, Train time: 122.00\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m#send data to cuda\u001b[39;00m\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\folder.py:247\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 247\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\IDE\\Anaconda\\lib\\site-packages\\PIL\\Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m   3234\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3236\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3238\u001b[0m preinit()\n\u001b[0;32m   3240\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 1\n",
    "start_time = time.time()\n",
    "# Loop over the dataset and train the model\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #send data to cuda\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training statistics\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train time: {:.2f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item(), (time.time()-start_time)/60))\n",
    "'''\n",
    "    # Evaluate the model on the validation dataset\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set: {:.2f}%'.format(100 * correct / total))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331136a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/89295], Accuracy: 89.00, Test time: 0.12\n",
      "Epoch [1/1], Step [200/89295], Accuracy: 89.50, Test time: 0.20\n",
      "Epoch [1/1], Step [300/89295], Accuracy: 88.67, Test time: 0.28\n",
      "Epoch [1/1], Step [400/89295], Accuracy: 88.25, Test time: 0.36\n",
      "Epoch [1/1], Step [500/89295], Accuracy: 89.20, Test time: 0.43\n",
      "Epoch [1/1], Step [600/89295], Accuracy: 89.50, Test time: 0.50\n",
      "Epoch [1/1], Step [700/89295], Accuracy: 89.71, Test time: 0.58\n",
      "Epoch [1/1], Step [800/89295], Accuracy: 90.00, Test time: 0.65\n",
      "Epoch [1/1], Step [900/89295], Accuracy: 89.89, Test time: 0.73\n",
      "Epoch [1/1], Step [1000/89295], Accuracy: 89.70, Test time: 0.81\n",
      "Epoch [1/1], Step [1100/89295], Accuracy: 89.82, Test time: 0.88\n",
      "Epoch [1/1], Step [1200/89295], Accuracy: 89.67, Test time: 0.98\n",
      "Epoch [1/1], Step [1300/89295], Accuracy: 90.00, Test time: 1.06\n",
      "Epoch [1/1], Step [1400/89295], Accuracy: 89.71, Test time: 1.13\n",
      "Epoch [1/1], Step [1500/89295], Accuracy: 89.80, Test time: 1.23\n",
      "Epoch [1/1], Step [1600/89295], Accuracy: 89.94, Test time: 1.30\n",
      "Epoch [1/1], Step [1700/89295], Accuracy: 90.06, Test time: 1.37\n",
      "Epoch [1/1], Step [1800/89295], Accuracy: 89.94, Test time: 1.44\n",
      "Epoch [1/1], Step [1900/89295], Accuracy: 90.00, Test time: 1.52\n",
      "Epoch [1/1], Step [2000/89295], Accuracy: 89.85, Test time: 1.64\n",
      "Epoch [1/1], Step [2100/89295], Accuracy: 89.71, Test time: 1.72\n",
      "Epoch [1/1], Step [2200/89295], Accuracy: 89.82, Test time: 1.83\n",
      "Epoch [1/1], Step [2300/89295], Accuracy: 89.91, Test time: 1.96\n",
      "Epoch [1/1], Step [2400/89295], Accuracy: 89.92, Test time: 2.06\n",
      "Epoch [1/1], Step [2500/89295], Accuracy: 89.96, Test time: 2.19\n",
      "Epoch [1/1], Step [2600/89295], Accuracy: 89.92, Test time: 2.29\n",
      "Epoch [1/1], Step [2700/89295], Accuracy: 90.11, Test time: 2.39\n",
      "Epoch [1/1], Step [2800/89295], Accuracy: 89.96, Test time: 2.54\n",
      "Epoch [1/1], Step [2900/89295], Accuracy: 90.07, Test time: 2.62\n",
      "Epoch [1/1], Step [3000/89295], Accuracy: 89.97, Test time: 2.76\n",
      "Epoch [1/1], Step [3100/89295], Accuracy: 89.97, Test time: 2.86\n",
      "Epoch [1/1], Step [3200/89295], Accuracy: 89.97, Test time: 2.97\n",
      "Epoch [1/1], Step [3300/89295], Accuracy: 89.97, Test time: 3.07\n",
      "Epoch [1/1], Step [3400/89295], Accuracy: 90.06, Test time: 3.19\n",
      "Epoch [1/1], Step [3500/89295], Accuracy: 90.06, Test time: 3.29\n",
      "Epoch [1/1], Step [3600/89295], Accuracy: 90.19, Test time: 3.46\n",
      "Epoch [1/1], Step [3700/89295], Accuracy: 90.32, Test time: 3.52\n",
      "Epoch [1/1], Step [3800/89295], Accuracy: 90.34, Test time: 3.66\n",
      "Epoch [1/1], Step [3900/89295], Accuracy: 90.33, Test time: 3.78\n",
      "Epoch [1/1], Step [4000/89295], Accuracy: 90.38, Test time: 4.01\n",
      "Epoch [1/1], Step [4100/89295], Accuracy: 90.49, Test time: 4.09\n",
      "Epoch [1/1], Step [4200/89295], Accuracy: 90.43, Test time: 4.16\n",
      "Epoch [1/1], Step [4300/89295], Accuracy: 90.44, Test time: 4.23\n",
      "Epoch [1/1], Step [4400/89295], Accuracy: 90.41, Test time: 4.29\n",
      "Epoch [1/1], Step [4500/89295], Accuracy: 90.44, Test time: 4.61\n",
      "Epoch [1/1], Step [4600/89295], Accuracy: 90.37, Test time: 4.67\n",
      "Epoch [1/1], Step [4700/89295], Accuracy: 90.40, Test time: 4.74\n",
      "Epoch [1/1], Step [4800/89295], Accuracy: 90.44, Test time: 4.80\n",
      "Epoch [1/1], Step [4900/89295], Accuracy: 90.53, Test time: 5.11\n",
      "Epoch [1/1], Step [5000/89295], Accuracy: 90.58, Test time: 5.18\n",
      "Epoch [1/1], Step [5100/89295], Accuracy: 90.37, Test time: 5.25\n",
      "Epoch [1/1], Step [5200/89295], Accuracy: 90.35, Test time: 5.31\n",
      "Epoch [1/1], Step [5300/89295], Accuracy: 90.36, Test time: 5.49\n",
      "Epoch [1/1], Step [5400/89295], Accuracy: 90.33, Test time: 5.56\n",
      "Epoch [1/1], Step [5500/89295], Accuracy: 90.33, Test time: 5.62\n",
      "Epoch [1/1], Step [5600/89295], Accuracy: 90.25, Test time: 5.68\n",
      "Epoch [1/1], Step [5700/89295], Accuracy: 90.23, Test time: 6.02\n",
      "Epoch [1/1], Step [5800/89295], Accuracy: 90.31, Test time: 6.18\n",
      "Epoch [1/1], Step [5900/89295], Accuracy: 90.37, Test time: 6.25\n",
      "Epoch [1/1], Step [6000/89295], Accuracy: 90.32, Test time: 6.31\n",
      "Epoch [1/1], Step [6100/89295], Accuracy: 90.36, Test time: 6.37\n",
      "Epoch [1/1], Step [6200/89295], Accuracy: 90.26, Test time: 6.72\n",
      "Epoch [1/1], Step [6300/89295], Accuracy: 90.22, Test time: 6.78\n",
      "Epoch [1/1], Step [6400/89295], Accuracy: 90.20, Test time: 6.85\n",
      "Epoch [1/1], Step [6500/89295], Accuracy: 90.23, Test time: 6.91\n",
      "Epoch [1/1], Step [6600/89295], Accuracy: 90.23, Test time: 6.98\n",
      "Epoch [1/1], Step [6700/89295], Accuracy: 90.21, Test time: 7.33\n",
      "Epoch [1/1], Step [6800/89295], Accuracy: 90.19, Test time: 7.40\n",
      "Epoch [1/1], Step [6900/89295], Accuracy: 90.19, Test time: 7.47\n",
      "Epoch [1/1], Step [7000/89295], Accuracy: 90.23, Test time: 7.64\n",
      "Epoch [1/1], Step [7100/89295], Accuracy: 90.24, Test time: 7.69\n",
      "Epoch [1/1], Step [7200/89295], Accuracy: 90.22, Test time: 7.75\n",
      "Epoch [1/1], Step [7300/89295], Accuracy: 90.18, Test time: 7.83\n",
      "Epoch [1/1], Step [7400/89295], Accuracy: 90.22, Test time: 8.10\n",
      "Epoch [1/1], Step [7500/89295], Accuracy: 90.27, Test time: 8.31\n",
      "Epoch [1/1], Step [7600/89295], Accuracy: 90.28, Test time: 8.37\n",
      "Epoch [1/1], Step [7700/89295], Accuracy: 90.19, Test time: 8.43\n",
      "Epoch [1/1], Step [7800/89295], Accuracy: 90.19, Test time: 8.49\n",
      "Epoch [1/1], Step [7900/89295], Accuracy: 90.22, Test time: 8.81\n",
      "Epoch [1/1], Step [8000/89295], Accuracy: 90.25, Test time: 8.87\n",
      "Epoch [1/1], Step [8100/89295], Accuracy: 90.23, Test time: 8.93\n",
      "Epoch [1/1], Step [8200/89295], Accuracy: 90.27, Test time: 8.98\n",
      "Epoch [1/1], Step [8300/89295], Accuracy: 90.24, Test time: 9.08\n",
      "Epoch [1/1], Step [8400/89295], Accuracy: 90.27, Test time: 9.37\n",
      "Epoch [1/1], Step [8500/89295], Accuracy: 90.25, Test time: 9.43\n",
      "Epoch [1/1], Step [8600/89295], Accuracy: 90.23, Test time: 9.49\n",
      "Epoch [1/1], Step [8700/89295], Accuracy: 90.23, Test time: 9.55\n",
      "Epoch [1/1], Step [8800/89295], Accuracy: 90.25, Test time: 9.84\n",
      "Epoch [1/1], Step [8900/89295], Accuracy: 90.22, Test time: 9.96\n",
      "Epoch [1/1], Step [9000/89295], Accuracy: 90.26, Test time: 10.02\n",
      "Epoch [1/1], Step [9100/89295], Accuracy: 90.26, Test time: 10.13\n",
      "Epoch [1/1], Step [9200/89295], Accuracy: 90.26, Test time: 10.28\n",
      "Epoch [1/1], Step [9300/89295], Accuracy: 90.22, Test time: 10.33\n",
      "Epoch [1/1], Step [9400/89295], Accuracy: 90.19, Test time: 10.40\n",
      "Epoch [1/1], Step [9500/89295], Accuracy: 90.18, Test time: 10.47\n",
      "Epoch [1/1], Step [9600/89295], Accuracy: 90.16, Test time: 10.77\n",
      "Epoch [1/1], Step [9700/89295], Accuracy: 90.16, Test time: 10.94\n",
      "Epoch [1/1], Step [9800/89295], Accuracy: 90.16, Test time: 11.00\n",
      "Epoch [1/1], Step [9900/89295], Accuracy: 90.16, Test time: 11.06\n",
      "Epoch [1/1], Step [10000/89295], Accuracy: 90.17, Test time: 11.34\n",
      "Epoch [1/1], Step [10100/89295], Accuracy: 90.16, Test time: 11.47\n",
      "Epoch [1/1], Step [10200/89295], Accuracy: 90.16, Test time: 11.53\n",
      "Epoch [1/1], Step [10300/89295], Accuracy: 90.19, Test time: 11.59\n",
      "Epoch [1/1], Step [10400/89295], Accuracy: 90.21, Test time: 11.77\n",
      "Epoch [1/1], Step [10500/89295], Accuracy: 90.22, Test time: 11.90\n",
      "Epoch [1/1], Step [10600/89295], Accuracy: 90.17, Test time: 11.97\n",
      "Epoch [1/1], Step [10700/89295], Accuracy: 90.19, Test time: 12.02\n",
      "Epoch [1/1], Step [10800/89295], Accuracy: 90.24, Test time: 12.09\n",
      "Epoch [1/1], Step [10900/89295], Accuracy: 90.20, Test time: 12.46\n",
      "Epoch [1/1], Step [11000/89295], Accuracy: 90.24, Test time: 12.52\n",
      "Epoch [1/1], Step [11100/89295], Accuracy: 90.23, Test time: 12.58\n",
      "Epoch [1/1], Step [11200/89295], Accuracy: 90.21, Test time: 12.63\n",
      "Epoch [1/1], Step [11300/89295], Accuracy: 90.17, Test time: 12.69\n",
      "Epoch [1/1], Step [11400/89295], Accuracy: 90.21, Test time: 13.03\n",
      "Epoch [1/1], Step [11500/89295], Accuracy: 90.26, Test time: 13.12\n",
      "Epoch [1/1], Step [11600/89295], Accuracy: 90.22, Test time: 13.18\n",
      "Epoch [1/1], Step [11700/89295], Accuracy: 90.26, Test time: 13.23\n",
      "Epoch [1/1], Step [11800/89295], Accuracy: 90.29, Test time: 13.51\n",
      "Epoch [1/1], Step [11900/89295], Accuracy: 90.27, Test time: 13.63\n",
      "Epoch [1/1], Step [12000/89295], Accuracy: 90.22, Test time: 13.69\n",
      "Epoch [1/1], Step [12100/89295], Accuracy: 90.23, Test time: 13.74\n",
      "Epoch [1/1], Step [12200/89295], Accuracy: 90.23, Test time: 13.83\n",
      "Epoch [1/1], Step [12300/89295], Accuracy: 90.24, Test time: 14.12\n",
      "Epoch [1/1], Step [12400/89295], Accuracy: 90.26, Test time: 14.18\n",
      "Epoch [1/1], Step [12500/89295], Accuracy: 90.24, Test time: 14.24\n",
      "Epoch [1/1], Step [12600/89295], Accuracy: 90.25, Test time: 14.29\n",
      "Epoch [1/1], Step [12700/89295], Accuracy: 90.24, Test time: 14.60\n",
      "Epoch [1/1], Step [12800/89295], Accuracy: 90.20, Test time: 14.66\n",
      "Epoch [1/1], Step [12900/89295], Accuracy: 90.22, Test time: 14.71\n",
      "Epoch [1/1], Step [13000/89295], Accuracy: 90.23, Test time: 14.77\n",
      "Epoch [1/1], Step [13100/89295], Accuracy: 90.23, Test time: 14.91\n",
      "Epoch [1/1], Step [13200/89295], Accuracy: 90.20, Test time: 15.19\n",
      "Epoch [1/1], Step [13300/89295], Accuracy: 90.20, Test time: 15.27\n",
      "Epoch [1/1], Step [13400/89295], Accuracy: 90.19, Test time: 15.32\n",
      "Epoch [1/1], Step [13500/89295], Accuracy: 90.20, Test time: 15.45\n",
      "Epoch [1/1], Step [13600/89295], Accuracy: 90.22, Test time: 15.63\n",
      "Epoch [1/1], Step [13700/89295], Accuracy: 90.24, Test time: 15.68\n",
      "Epoch [1/1], Step [13800/89295], Accuracy: 90.23, Test time: 15.73\n",
      "Epoch [1/1], Step [13900/89295], Accuracy: 90.26, Test time: 15.84\n",
      "Epoch [1/1], Step [14000/89295], Accuracy: 90.26, Test time: 16.12\n",
      "Epoch [1/1], Step [14100/89295], Accuracy: 90.27, Test time: 16.21\n",
      "Epoch [1/1], Step [14200/89295], Accuracy: 90.25, Test time: 16.26\n",
      "Epoch [1/1], Step [14300/89295], Accuracy: 90.24, Test time: 16.31\n",
      "Epoch [1/1], Step [14400/89295], Accuracy: 90.22, Test time: 16.51\n",
      "Epoch [1/1], Step [14500/89295], Accuracy: 90.22, Test time: 16.72\n",
      "Epoch [1/1], Step [14600/89295], Accuracy: 90.20, Test time: 16.77\n",
      "Epoch [1/1], Step [14700/89295], Accuracy: 90.19, Test time: 16.82\n",
      "Epoch [1/1], Step [14800/89295], Accuracy: 90.20, Test time: 16.87\n",
      "Epoch [1/1], Step [14900/89295], Accuracy: 90.21, Test time: 17.14\n",
      "Epoch [1/1], Step [15000/89295], Accuracy: 90.21, Test time: 17.32\n",
      "Epoch [1/1], Step [15100/89295], Accuracy: 90.23, Test time: 17.37\n",
      "Epoch [1/1], Step [15200/89295], Accuracy: 90.22, Test time: 17.42\n",
      "Epoch [1/1], Step [15300/89295], Accuracy: 90.22, Test time: 17.58\n",
      "Epoch [1/1], Step [15400/89295], Accuracy: 90.23, Test time: 17.77\n",
      "Epoch [1/1], Step [15500/89295], Accuracy: 90.26, Test time: 17.83\n",
      "Epoch [1/1], Step [15600/89295], Accuracy: 90.26, Test time: 17.88\n",
      "Epoch [1/1], Step [15700/89295], Accuracy: 90.29, Test time: 17.93\n",
      "Epoch [1/1], Step [15800/89295], Accuracy: 90.30, Test time: 17.98\n",
      "Epoch [1/1], Step [15900/89295], Accuracy: 90.31, Test time: 18.28\n",
      "Epoch [1/1], Step [16000/89295], Accuracy: 90.30, Test time: 18.42\n",
      "Epoch [1/1], Step [16100/89295], Accuracy: 90.29, Test time: 18.47\n",
      "Epoch [1/1], Step [16200/89295], Accuracy: 90.28, Test time: 18.52\n",
      "Epoch [1/1], Step [16300/89295], Accuracy: 90.31, Test time: 18.57\n",
      "Epoch [1/1], Step [16400/89295], Accuracy: 90.27, Test time: 18.88\n",
      "Epoch [1/1], Step [16500/89295], Accuracy: 90.28, Test time: 19.06\n",
      "Epoch [1/1], Step [16600/89295], Accuracy: 90.29, Test time: 19.11\n",
      "Epoch [1/1], Step [16700/89295], Accuracy: 90.30, Test time: 19.16\n",
      "Epoch [1/1], Step [16800/89295], Accuracy: 90.29, Test time: 19.41\n",
      "Epoch [1/1], Step [16900/89295], Accuracy: 90.28, Test time: 19.52\n",
      "Epoch [1/1], Step [17000/89295], Accuracy: 90.29, Test time: 19.57\n",
      "Epoch [1/1], Step [17100/89295], Accuracy: 90.27, Test time: 19.62\n",
      "Epoch [1/1], Step [17200/89295], Accuracy: 90.23, Test time: 19.67\n",
      "Epoch [1/1], Step [17300/89295], Accuracy: 90.21, Test time: 19.72\n",
      "Epoch [1/1], Step [17400/89295], Accuracy: 90.20, Test time: 20.09\n",
      "Epoch [1/1], Step [17500/89295], Accuracy: 90.19, Test time: 20.17\n",
      "Epoch [1/1], Step [17600/89295], Accuracy: 90.20, Test time: 20.22\n",
      "Epoch [1/1], Step [17700/89295], Accuracy: 90.20, Test time: 20.27\n",
      "Epoch [1/1], Step [17800/89295], Accuracy: 90.17, Test time: 20.38\n",
      "Epoch [1/1], Step [17900/89295], Accuracy: 90.17, Test time: 20.66\n",
      "Epoch [1/1], Step [18000/89295], Accuracy: 90.19, Test time: 20.78\n",
      "Epoch [1/1], Step [18100/89295], Accuracy: 90.18, Test time: 20.83\n",
      "Epoch [1/1], Step [18200/89295], Accuracy: 90.20, Test time: 20.88\n",
      "Epoch [1/1], Step [18300/89295], Accuracy: 90.21, Test time: 21.08\n",
      "Epoch [1/1], Step [18400/89295], Accuracy: 90.24, Test time: 21.26\n",
      "Epoch [1/1], Step [18500/89295], Accuracy: 90.28, Test time: 21.31\n",
      "Epoch [1/1], Step [18600/89295], Accuracy: 90.30, Test time: 21.37\n",
      "Epoch [1/1], Step [18700/89295], Accuracy: 90.32, Test time: 21.41\n",
      "Epoch [1/1], Step [18800/89295], Accuracy: 90.31, Test time: 21.56\n",
      "Epoch [1/1], Step [18900/89295], Accuracy: 90.26, Test time: 21.84\n",
      "Epoch [1/1], Step [19000/89295], Accuracy: 90.26, Test time: 22.00\n",
      "Epoch [1/1], Step [19100/89295], Accuracy: 90.27, Test time: 22.05\n",
      "Epoch [1/1], Step [19200/89295], Accuracy: 90.28, Test time: 22.11\n",
      "Epoch [1/1], Step [19300/89295], Accuracy: 90.27, Test time: 22.24\n",
      "Epoch [1/1], Step [19400/89295], Accuracy: 90.28, Test time: 22.48\n",
      "Epoch [1/1], Step [19500/89295], Accuracy: 90.30, Test time: 22.53\n",
      "Epoch [1/1], Step [19600/89295], Accuracy: 90.32, Test time: 22.58\n",
      "Epoch [1/1], Step [19700/89295], Accuracy: 90.34, Test time: 22.63\n",
      "Epoch [1/1], Step [19800/89295], Accuracy: 90.34, Test time: 22.68\n",
      "Epoch [1/1], Step [19900/89295], Accuracy: 90.34, Test time: 22.87\n",
      "Epoch [1/1], Step [20000/89295], Accuracy: 90.34, Test time: 23.12\n",
      "Epoch [1/1], Step [20100/89295], Accuracy: 90.34, Test time: 23.20\n",
      "Epoch [1/1], Step [20200/89295], Accuracy: 90.32, Test time: 23.25\n",
      "Epoch [1/1], Step [20300/89295], Accuracy: 90.33, Test time: 23.30\n",
      "Epoch [1/1], Step [20400/89295], Accuracy: 90.35, Test time: 23.57\n",
      "Epoch [1/1], Step [20500/89295], Accuracy: 90.35, Test time: 23.69\n",
      "Epoch [1/1], Step [20600/89295], Accuracy: 90.34, Test time: 23.74\n",
      "Epoch [1/1], Step [20700/89295], Accuracy: 90.34, Test time: 23.79\n",
      "Epoch [1/1], Step [20800/89295], Accuracy: 90.34, Test time: 23.85\n",
      "Epoch [1/1], Step [20900/89295], Accuracy: 90.33, Test time: 24.20\n",
      "Epoch [1/1], Step [21000/89295], Accuracy: 90.32, Test time: 24.25\n",
      "Epoch [1/1], Step [21100/89295], Accuracy: 90.34, Test time: 24.30\n",
      "Epoch [1/1], Step [21200/89295], Accuracy: 90.34, Test time: 24.34\n",
      "Epoch [1/1], Step [21300/89295], Accuracy: 90.34, Test time: 24.57\n",
      "Epoch [1/1], Step [21400/89295], Accuracy: 90.34, Test time: 24.80\n",
      "Epoch [1/1], Step [21500/89295], Accuracy: 90.35, Test time: 24.87\n",
      "Epoch [1/1], Step [21600/89295], Accuracy: 90.34, Test time: 24.92\n",
      "Epoch [1/1], Step [21700/89295], Accuracy: 90.34, Test time: 24.97\n",
      "Epoch [1/1], Step [21800/89295], Accuracy: 90.32, Test time: 25.04\n",
      "Epoch [1/1], Step [21900/89295], Accuracy: 90.32, Test time: 25.35\n",
      "Epoch [1/1], Step [22000/89295], Accuracy: 90.31, Test time: 25.44\n",
      "Epoch [1/1], Step [22100/89295], Accuracy: 90.30, Test time: 25.48\n",
      "Epoch [1/1], Step [22200/89295], Accuracy: 90.30, Test time: 25.53\n",
      "Epoch [1/1], Step [22300/89295], Accuracy: 90.29, Test time: 25.58\n",
      "Epoch [1/1], Step [22400/89295], Accuracy: 90.30, Test time: 25.94\n",
      "Epoch [1/1], Step [22500/89295], Accuracy: 90.31, Test time: 26.03\n",
      "Epoch [1/1], Step [22600/89295], Accuracy: 90.31, Test time: 26.07\n",
      "Epoch [1/1], Step [22700/89295], Accuracy: 90.32, Test time: 26.12\n",
      "Epoch [1/1], Step [22800/89295], Accuracy: 90.33, Test time: 26.17\n",
      "Epoch [1/1], Step [22900/89295], Accuracy: 90.34, Test time: 26.52\n",
      "Epoch [1/1], Step [23000/89295], Accuracy: 90.37, Test time: 26.64\n",
      "Epoch [1/1], Step [23100/89295], Accuracy: 90.38, Test time: 26.69\n",
      "Epoch [1/1], Step [23200/89295], Accuracy: 90.38, Test time: 26.74\n",
      "Epoch [1/1], Step [23300/89295], Accuracy: 90.37, Test time: 26.97\n",
      "Epoch [1/1], Step [23400/89295], Accuracy: 90.37, Test time: 27.10\n",
      "Epoch [1/1], Step [23500/89295], Accuracy: 90.36, Test time: 27.15\n",
      "Epoch [1/1], Step [23600/89295], Accuracy: 90.36, Test time: 27.20\n",
      "Epoch [1/1], Step [23700/89295], Accuracy: 90.36, Test time: 27.34\n",
      "Epoch [1/1], Step [23800/89295], Accuracy: 90.36, Test time: 27.58\n",
      "Epoch [1/1], Step [23900/89295], Accuracy: 90.35, Test time: 27.63\n",
      "Epoch [1/1], Step [24000/89295], Accuracy: 90.36, Test time: 27.68\n",
      "Epoch [1/1], Step [24100/89295], Accuracy: 90.38, Test time: 27.73\n",
      "Epoch [1/1], Step [24200/89295], Accuracy: 90.40, Test time: 27.83\n",
      "Epoch [1/1], Step [24300/89295], Accuracy: 90.38, Test time: 28.19\n",
      "Epoch [1/1], Step [24400/89295], Accuracy: 90.37, Test time: 28.25\n",
      "Epoch [1/1], Step [24500/89295], Accuracy: 90.35, Test time: 28.30\n",
      "Epoch [1/1], Step [24600/89295], Accuracy: 90.35, Test time: 28.39\n",
      "Epoch [1/1], Step [24700/89295], Accuracy: 90.33, Test time: 28.50\n",
      "Epoch [1/1], Step [24800/89295], Accuracy: 90.33, Test time: 28.56\n",
      "Epoch [1/1], Step [24900/89295], Accuracy: 90.35, Test time: 28.61\n",
      "Epoch [1/1], Step [25000/89295], Accuracy: 90.33, Test time: 28.71\n",
      "Epoch [1/1], Step [25100/89295], Accuracy: 90.33, Test time: 28.96\n",
      "Epoch [1/1], Step [25200/89295], Accuracy: 90.33, Test time: 29.19\n",
      "Epoch [1/1], Step [25300/89295], Accuracy: 90.34, Test time: 29.24\n",
      "Epoch [1/1], Step [25400/89295], Accuracy: 90.32, Test time: 29.28\n",
      "Epoch [1/1], Step [25500/89295], Accuracy: 90.32, Test time: 29.34\n",
      "Epoch [1/1], Step [25600/89295], Accuracy: 90.30, Test time: 29.39\n",
      "Epoch [1/1], Step [25700/89295], Accuracy: 90.28, Test time: 29.69\n",
      "Epoch [1/1], Step [25800/89295], Accuracy: 90.29, Test time: 29.84\n",
      "Epoch [1/1], Step [25900/89295], Accuracy: 90.30, Test time: 29.89\n",
      "Epoch [1/1], Step [26000/89295], Accuracy: 90.29, Test time: 29.94\n",
      "Epoch [1/1], Step [26100/89295], Accuracy: 90.31, Test time: 30.16\n",
      "Epoch [1/1], Step [26200/89295], Accuracy: 90.31, Test time: 30.34\n",
      "Epoch [1/1], Step [26300/89295], Accuracy: 90.30, Test time: 30.39\n",
      "Epoch [1/1], Step [26400/89295], Accuracy: 90.32, Test time: 30.44\n",
      "Epoch [1/1], Step [26500/89295], Accuracy: 90.32, Test time: 30.49\n",
      "Epoch [1/1], Step [26600/89295], Accuracy: 90.30, Test time: 30.54\n",
      "Epoch [1/1], Step [26700/89295], Accuracy: 90.31, Test time: 30.87\n",
      "Epoch [1/1], Step [26800/89295], Accuracy: 90.32, Test time: 31.00\n",
      "Epoch [1/1], Step [26900/89295], Accuracy: 90.32, Test time: 31.05\n",
      "Epoch [1/1], Step [27000/89295], Accuracy: 90.32, Test time: 31.10\n",
      "Epoch [1/1], Step [27100/89295], Accuracy: 90.33, Test time: 31.20\n",
      "Epoch [1/1], Step [27200/89295], Accuracy: 90.33, Test time: 31.53\n",
      "Epoch [1/1], Step [27300/89295], Accuracy: 90.35, Test time: 31.68\n",
      "Epoch [1/1], Step [27400/89295], Accuracy: 90.36, Test time: 31.73\n",
      "Epoch [1/1], Step [27500/89295], Accuracy: 90.36, Test time: 31.79\n",
      "Epoch [1/1], Step [27600/89295], Accuracy: 90.37, Test time: 31.91\n",
      "Epoch [1/1], Step [27700/89295], Accuracy: 90.38, Test time: 32.17\n",
      "Epoch [1/1], Step [27800/89295], Accuracy: 90.38, Test time: 32.22\n",
      "Epoch [1/1], Step [27900/89295], Accuracy: 90.38, Test time: 32.27\n",
      "Epoch [1/1], Step [28000/89295], Accuracy: 90.39, Test time: 32.32\n",
      "Epoch [1/1], Step [28100/89295], Accuracy: 90.39, Test time: 32.38\n",
      "Epoch [1/1], Step [28200/89295], Accuracy: 90.40, Test time: 32.71\n",
      "Epoch [1/1], Step [28300/89295], Accuracy: 90.38, Test time: 32.90\n",
      "Epoch [1/1], Step [28400/89295], Accuracy: 90.38, Test time: 32.96\n",
      "Epoch [1/1], Step [28500/89295], Accuracy: 90.39, Test time: 33.12\n",
      "Epoch [1/1], Step [28600/89295], Accuracy: 90.38, Test time: 33.18\n",
      "Epoch [1/1], Step [28700/89295], Accuracy: 90.38, Test time: 33.23\n",
      "Epoch [1/1], Step [28800/89295], Accuracy: 90.36, Test time: 33.28\n",
      "Epoch [1/1], Step [28900/89295], Accuracy: 90.36, Test time: 33.53\n",
      "Epoch [1/1], Step [29000/89295], Accuracy: 90.36, Test time: 33.84\n",
      "Epoch [1/1], Step [29100/89295], Accuracy: 90.36, Test time: 33.92\n",
      "Epoch [1/1], Step [29200/89295], Accuracy: 90.37, Test time: 33.98\n",
      "Epoch [1/1], Step [29300/89295], Accuracy: 90.38, Test time: 34.03\n",
      "Epoch [1/1], Step [29400/89295], Accuracy: 90.37, Test time: 34.36\n",
      "Epoch [1/1], Step [29500/89295], Accuracy: 90.35, Test time: 34.56\n",
      "Epoch [1/1], Step [29600/89295], Accuracy: 90.35, Test time: 34.61\n",
      "Epoch [1/1], Step [29700/89295], Accuracy: 90.35, Test time: 34.66\n",
      "Epoch [1/1], Step [29800/89295], Accuracy: 90.35, Test time: 34.72\n",
      "Epoch [1/1], Step [29900/89295], Accuracy: 90.36, Test time: 34.81\n",
      "Epoch [1/1], Step [30000/89295], Accuracy: 90.37, Test time: 35.12\n",
      "Epoch [1/1], Step [30100/89295], Accuracy: 90.38, Test time: 35.24\n",
      "Epoch [1/1], Step [30200/89295], Accuracy: 90.39, Test time: 35.30\n",
      "Epoch [1/1], Step [30300/89295], Accuracy: 90.39, Test time: 35.50\n",
      "Epoch [1/1], Step [30400/89295], Accuracy: 90.39, Test time: 35.55\n",
      "Epoch [1/1], Step [30500/89295], Accuracy: 90.39, Test time: 35.60\n",
      "Epoch [1/1], Step [30600/89295], Accuracy: 90.38, Test time: 35.82\n",
      "Epoch [1/1], Step [30700/89295], Accuracy: 90.39, Test time: 36.04\n",
      "Epoch [1/1], Step [30800/89295], Accuracy: 90.39, Test time: 36.09\n",
      "Epoch [1/1], Step [30900/89295], Accuracy: 90.39, Test time: 36.14\n",
      "Epoch [1/1], Step [31000/89295], Accuracy: 90.41, Test time: 36.20\n",
      "Epoch [1/1], Step [31100/89295], Accuracy: 90.40, Test time: 36.25\n",
      "Epoch [1/1], Step [31200/89295], Accuracy: 90.39, Test time: 36.63\n",
      "Epoch [1/1], Step [31300/89295], Accuracy: 90.40, Test time: 36.86\n",
      "Epoch [1/1], Step [31400/89295], Accuracy: 90.39, Test time: 36.98\n",
      "Epoch [1/1], Step [31500/89295], Accuracy: 90.39, Test time: 37.03\n",
      "Epoch [1/1], Step [31600/89295], Accuracy: 90.40, Test time: 37.08\n",
      "Epoch [1/1], Step [31700/89295], Accuracy: 90.41, Test time: 37.15\n",
      "Epoch [1/1], Step [31800/89295], Accuracy: 90.42, Test time: 37.25\n",
      "Epoch [1/1], Step [31900/89295], Accuracy: 90.43, Test time: 37.61\n",
      "Epoch [1/1], Step [32000/89295], Accuracy: 90.42, Test time: 37.79\n",
      "Epoch [1/1], Step [32100/89295], Accuracy: 90.41, Test time: 37.90\n",
      "Epoch [1/1], Step [32200/89295], Accuracy: 90.41, Test time: 37.95\n",
      "Epoch [1/1], Step [32300/89295], Accuracy: 90.41, Test time: 38.13\n",
      "Epoch [1/1], Step [32400/89295], Accuracy: 90.41, Test time: 38.19\n",
      "Epoch [1/1], Step [32500/89295], Accuracy: 90.42, Test time: 38.28\n",
      "Epoch [1/1], Step [32600/89295], Accuracy: 90.43, Test time: 38.36\n",
      "Epoch [1/1], Step [32700/89295], Accuracy: 90.41, Test time: 38.62\n",
      "Epoch [1/1], Step [32800/89295], Accuracy: 90.41, Test time: 38.71\n",
      "Epoch [1/1], Step [32900/89295], Accuracy: 90.41, Test time: 38.85\n",
      "Epoch [1/1], Step [33000/89295], Accuracy: 90.41, Test time: 38.92\n",
      "Epoch [1/1], Step [33100/89295], Accuracy: 90.42, Test time: 39.19\n",
      "Epoch [1/1], Step [33200/89295], Accuracy: 90.43, Test time: 39.28\n",
      "Epoch [1/1], Step [33300/89295], Accuracy: 90.43, Test time: 39.36\n",
      "Epoch [1/1], Step [33400/89295], Accuracy: 90.44, Test time: 39.55\n",
      "Epoch [1/1], Step [33500/89295], Accuracy: 90.44, Test time: 39.62\n",
      "Epoch [1/1], Step [33600/89295], Accuracy: 90.45, Test time: 39.68\n",
      "Epoch [1/1], Step [33700/89295], Accuracy: 90.45, Test time: 39.89\n",
      "Epoch [1/1], Step [33800/89295], Accuracy: 90.45, Test time: 39.97\n",
      "Epoch [1/1], Step [33900/89295], Accuracy: 90.45, Test time: 40.10\n",
      "Epoch [1/1], Step [34000/89295], Accuracy: 90.44, Test time: 40.23\n",
      "Epoch [1/1], Step [34100/89295], Accuracy: 90.44, Test time: 40.31\n",
      "Epoch [1/1], Step [34200/89295], Accuracy: 90.44, Test time: 40.46\n",
      "Epoch [1/1], Step [34300/89295], Accuracy: 90.45, Test time: 40.56\n",
      "Epoch [1/1], Step [34400/89295], Accuracy: 90.46, Test time: 40.67\n",
      "Epoch [1/1], Step [34500/89295], Accuracy: 90.45, Test time: 40.83\n",
      "Epoch [1/1], Step [34600/89295], Accuracy: 90.45, Test time: 40.92\n",
      "Epoch [1/1], Step [34700/89295], Accuracy: 90.45, Test time: 41.04\n",
      "Epoch [1/1], Step [34800/89295], Accuracy: 90.46, Test time: 41.25\n",
      "Epoch [1/1], Step [34900/89295], Accuracy: 90.44, Test time: 41.31\n",
      "Epoch [1/1], Step [35000/89295], Accuracy: 90.44, Test time: 41.48\n",
      "Epoch [1/1], Step [35100/89295], Accuracy: 90.44, Test time: 41.60\n",
      "Epoch [1/1], Step [35200/89295], Accuracy: 90.43, Test time: 41.69\n",
      "Epoch [1/1], Step [35300/89295], Accuracy: 90.43, Test time: 41.76\n",
      "Epoch [1/1], Step [35400/89295], Accuracy: 90.43, Test time: 41.89\n",
      "Epoch [1/1], Step [35500/89295], Accuracy: 90.43, Test time: 41.94\n",
      "Epoch [1/1], Step [35600/89295], Accuracy: 90.45, Test time: 42.01\n",
      "Epoch [1/1], Step [35700/89295], Accuracy: 90.45, Test time: 42.26\n",
      "Epoch [1/1], Step [35800/89295], Accuracy: 90.44, Test time: 42.59\n",
      "Epoch [1/1], Step [35900/89295], Accuracy: 90.43, Test time: 42.66\n",
      "Epoch [1/1], Step [36000/89295], Accuracy: 90.42, Test time: 42.71\n",
      "Epoch [1/1], Step [36100/89295], Accuracy: 90.42, Test time: 42.76\n",
      "Epoch [1/1], Step [36200/89295], Accuracy: 90.40, Test time: 42.81\n",
      "Epoch [1/1], Step [36300/89295], Accuracy: 90.39, Test time: 42.86\n",
      "Epoch [1/1], Step [36400/89295], Accuracy: 90.40, Test time: 43.01\n",
      "Epoch [1/1], Step [36500/89295], Accuracy: 90.38, Test time: 43.32\n",
      "Epoch [1/1], Step [36600/89295], Accuracy: 90.38, Test time: 43.64\n",
      "Epoch [1/1], Step [36700/89295], Accuracy: 90.38, Test time: 43.69\n",
      "Epoch [1/1], Step [36800/89295], Accuracy: 90.38, Test time: 43.74\n",
      "Epoch [1/1], Step [36900/89295], Accuracy: 90.40, Test time: 43.79\n",
      "Epoch [1/1], Step [37000/89295], Accuracy: 90.40, Test time: 44.01\n",
      "Epoch [1/1], Step [37100/89295], Accuracy: 90.41, Test time: 44.29\n",
      "Epoch [1/1], Step [37200/89295], Accuracy: 90.42, Test time: 44.42\n",
      "Epoch [1/1], Step [37300/89295], Accuracy: 90.42, Test time: 44.57\n",
      "Epoch [1/1], Step [37400/89295], Accuracy: 90.42, Test time: 44.62\n",
      "Epoch [1/1], Step [37500/89295], Accuracy: 90.43, Test time: 44.67\n",
      "Epoch [1/1], Step [37600/89295], Accuracy: 90.42, Test time: 44.72\n",
      "Epoch [1/1], Step [37700/89295], Accuracy: 90.42, Test time: 45.05\n",
      "Epoch [1/1], Step [37800/89295], Accuracy: 90.42, Test time: 45.17\n",
      "Epoch [1/1], Step [37900/89295], Accuracy: 90.41, Test time: 45.30\n",
      "Epoch [1/1], Step [38000/89295], Accuracy: 90.42, Test time: 45.43\n",
      "Epoch [1/1], Step [38100/89295], Accuracy: 90.42, Test time: 45.48\n",
      "Epoch [1/1], Step [38200/89295], Accuracy: 90.42, Test time: 45.53\n",
      "Epoch [1/1], Step [38300/89295], Accuracy: 90.42, Test time: 45.58\n",
      "Epoch [1/1], Step [38400/89295], Accuracy: 90.43, Test time: 45.92\n",
      "Epoch [1/1], Step [38500/89295], Accuracy: 90.44, Test time: 46.18\n",
      "Epoch [1/1], Step [38600/89295], Accuracy: 90.43, Test time: 46.22\n",
      "Epoch [1/1], Step [38700/89295], Accuracy: 90.44, Test time: 46.27\n",
      "Epoch [1/1], Step [38800/89295], Accuracy: 90.45, Test time: 46.33\n",
      "Epoch [1/1], Step [38900/89295], Accuracy: 90.46, Test time: 46.39\n",
      "Epoch [1/1], Step [39000/89295], Accuracy: 90.47, Test time: 46.56\n",
      "Epoch [1/1], Step [39100/89295], Accuracy: 90.47, Test time: 46.87\n",
      "Epoch [1/1], Step [39200/89295], Accuracy: 90.48, Test time: 46.97\n",
      "Epoch [1/1], Step [39300/89295], Accuracy: 90.48, Test time: 47.10\n",
      "Epoch [1/1], Step [39400/89295], Accuracy: 90.47, Test time: 47.15\n",
      "Epoch [1/1], Step [39500/89295], Accuracy: 90.48, Test time: 47.20\n",
      "Epoch [1/1], Step [39600/89295], Accuracy: 90.46, Test time: 47.25\n",
      "Epoch [1/1], Step [39700/89295], Accuracy: 90.46, Test time: 47.30\n",
      "Epoch [1/1], Step [39800/89295], Accuracy: 90.45, Test time: 47.55\n",
      "Epoch [1/1], Step [39900/89295], Accuracy: 90.45, Test time: 47.86\n",
      "Epoch [1/1], Step [40000/89295], Accuracy: 90.44, Test time: 48.16\n",
      "Epoch [1/1], Step [40100/89295], Accuracy: 90.44, Test time: 48.44\n",
      "Epoch [1/1], Step [40200/89295], Accuracy: 90.44, Test time: 48.72\n",
      "Epoch [1/1], Step [40300/89295], Accuracy: 90.44, Test time: 49.02\n",
      "Epoch [1/1], Step [40400/89295], Accuracy: 90.45, Test time: 49.33\n",
      "Epoch [1/1], Step [40500/89295], Accuracy: 90.44, Test time: 49.65\n",
      "Epoch [1/1], Step [40600/89295], Accuracy: 90.44, Test time: 49.98\n",
      "Epoch [1/1], Step [40700/89295], Accuracy: 90.44, Test time: 50.14\n",
      "Epoch [1/1], Step [40800/89295], Accuracy: 90.44, Test time: 50.37\n",
      "Epoch [1/1], Step [40900/89295], Accuracy: 90.44, Test time: 50.48\n",
      "Epoch [1/1], Step [41000/89295], Accuracy: 90.45, Test time: 50.52\n",
      "Epoch [1/1], Step [41100/89295], Accuracy: 90.45, Test time: 50.81\n",
      "Epoch [1/1], Step [41200/89295], Accuracy: 90.44, Test time: 51.08\n",
      "Epoch [1/1], Step [41300/89295], Accuracy: 90.46, Test time: 51.13\n",
      "Epoch [1/1], Step [41400/89295], Accuracy: 90.46, Test time: 51.18\n",
      "Epoch [1/1], Step [41500/89295], Accuracy: 90.46, Test time: 51.23\n",
      "Epoch [1/1], Step [41600/89295], Accuracy: 90.46, Test time: 51.38\n",
      "Epoch [1/1], Step [41700/89295], Accuracy: 90.46, Test time: 51.68\n",
      "Epoch [1/1], Step [41800/89295], Accuracy: 90.46, Test time: 52.00\n",
      "Epoch [1/1], Step [41900/89295], Accuracy: 90.46, Test time: 52.32\n",
      "Epoch [1/1], Step [42000/89295], Accuracy: 90.46, Test time: 52.62\n",
      "Epoch [1/1], Step [42100/89295], Accuracy: 90.47, Test time: 52.98\n",
      "Epoch [1/1], Step [42200/89295], Accuracy: 90.47, Test time: 53.32\n",
      "Epoch [1/1], Step [42300/89295], Accuracy: 90.47, Test time: 53.68\n",
      "Epoch [1/1], Step [42400/89295], Accuracy: 90.48, Test time: 54.03\n",
      "Epoch [1/1], Step [42500/89295], Accuracy: 90.47, Test time: 54.37\n",
      "Epoch [1/1], Step [42600/89295], Accuracy: 90.48, Test time: 54.71\n",
      "Epoch [1/1], Step [42700/89295], Accuracy: 90.48, Test time: 55.05\n",
      "Epoch [1/1], Step [42800/89295], Accuracy: 90.49, Test time: 55.82\n",
      "Epoch [1/1], Step [42900/89295], Accuracy: 90.49, Test time: 56.15\n",
      "Epoch [1/1], Step [43000/89295], Accuracy: 90.48, Test time: 56.45\n",
      "Epoch [1/1], Step [43100/89295], Accuracy: 90.48, Test time: 56.71\n",
      "Epoch [1/1], Step [43200/89295], Accuracy: 90.47, Test time: 57.00\n",
      "Epoch [1/1], Step [43300/89295], Accuracy: 90.48, Test time: 57.28\n",
      "Epoch [1/1], Step [43400/89295], Accuracy: 90.47, Test time: 57.61\n",
      "Epoch [1/1], Step [43500/89295], Accuracy: 90.47, Test time: 57.94\n",
      "Epoch [1/1], Step [43600/89295], Accuracy: 90.47, Test time: 58.49\n",
      "Epoch [1/1], Step [43700/89295], Accuracy: 90.47, Test time: 58.63\n",
      "Epoch [1/1], Step [43800/89295], Accuracy: 90.45, Test time: 58.69\n",
      "Epoch [1/1], Step [43900/89295], Accuracy: 90.44, Test time: 58.74\n",
      "Epoch [1/1], Step [44000/89295], Accuracy: 90.43, Test time: 58.79\n",
      "Epoch [1/1], Step [44100/89295], Accuracy: 90.42, Test time: 58.88\n",
      "Epoch [1/1], Step [44200/89295], Accuracy: 90.43, Test time: 59.15\n",
      "Epoch [1/1], Step [44300/89295], Accuracy: 90.43, Test time: 59.22\n",
      "Epoch [1/1], Step [44400/89295], Accuracy: 90.43, Test time: 59.27\n",
      "Epoch [1/1], Step [44500/89295], Accuracy: 90.42, Test time: 59.33\n",
      "Epoch [1/1], Step [44600/89295], Accuracy: 90.42, Test time: 59.37\n",
      "Epoch [1/1], Step [44700/89295], Accuracy: 90.42, Test time: 59.73\n",
      "Epoch [1/1], Step [44800/89295], Accuracy: 90.43, Test time: 59.81\n",
      "Epoch [1/1], Step [44900/89295], Accuracy: 90.43, Test time: 59.86\n",
      "Epoch [1/1], Step [45000/89295], Accuracy: 90.43, Test time: 59.91\n",
      "Epoch [1/1], Step [45100/89295], Accuracy: 90.43, Test time: 59.96\n",
      "Epoch [1/1], Step [45200/89295], Accuracy: 90.44, Test time: 60.20\n",
      "Epoch [1/1], Step [45300/89295], Accuracy: 90.41, Test time: 60.40\n",
      "Epoch [1/1], Step [45400/89295], Accuracy: 90.40, Test time: 60.45\n",
      "Epoch [1/1], Step [45500/89295], Accuracy: 90.40, Test time: 60.50\n",
      "Epoch [1/1], Step [45600/89295], Accuracy: 90.39, Test time: 60.67\n",
      "Epoch [1/1], Step [45700/89295], Accuracy: 90.40, Test time: 60.72\n",
      "Epoch [1/1], Step [45800/89295], Accuracy: 90.40, Test time: 60.77\n",
      "Epoch [1/1], Step [45900/89295], Accuracy: 90.41, Test time: 60.86\n",
      "Epoch [1/1], Step [46000/89295], Accuracy: 90.41, Test time: 61.15\n",
      "Epoch [1/1], Step [46100/89295], Accuracy: 90.41, Test time: 61.34\n",
      "Epoch [1/1], Step [46200/89295], Accuracy: 90.41, Test time: 61.39\n",
      "Epoch [1/1], Step [46300/89295], Accuracy: 90.41, Test time: 61.51\n",
      "Epoch [1/1], Step [46400/89295], Accuracy: 90.41, Test time: 61.60\n",
      "Epoch [1/1], Step [46500/89295], Accuracy: 90.41, Test time: 61.65\n",
      "Epoch [1/1], Step [46600/89295], Accuracy: 90.41, Test time: 61.70\n",
      "Epoch [1/1], Step [46700/89295], Accuracy: 90.40, Test time: 61.90\n",
      "Epoch [1/1], Step [46800/89295], Accuracy: 90.40, Test time: 62.16\n",
      "Epoch [1/1], Step [46900/89295], Accuracy: 90.40, Test time: 62.21\n",
      "Epoch [1/1], Step [47000/89295], Accuracy: 90.40, Test time: 62.26\n",
      "Epoch [1/1], Step [47100/89295], Accuracy: 90.39, Test time: 62.31\n",
      "Epoch [1/1], Step [47200/89295], Accuracy: 90.40, Test time: 62.55\n",
      "Epoch [1/1], Step [47300/89295], Accuracy: 90.40, Test time: 62.76\n",
      "Epoch [1/1], Step [47400/89295], Accuracy: 90.41, Test time: 62.81\n",
      "Epoch [1/1], Step [47500/89295], Accuracy: 90.41, Test time: 62.86\n",
      "Epoch [1/1], Step [47600/89295], Accuracy: 90.41, Test time: 63.25\n",
      "Epoch [1/1], Step [47700/89295], Accuracy: 90.40, Test time: 63.40\n",
      "Epoch [1/1], Step [47800/89295], Accuracy: 90.40, Test time: 63.51\n",
      "Epoch [1/1], Step [47900/89295], Accuracy: 90.40, Test time: 63.56\n",
      "Epoch [1/1], Step [48000/89295], Accuracy: 90.39, Test time: 63.60\n",
      "Epoch [1/1], Step [48100/89295], Accuracy: 90.40, Test time: 63.66\n",
      "Epoch [1/1], Step [48200/89295], Accuracy: 90.39, Test time: 63.70\n",
      "Epoch [1/1], Step [48300/89295], Accuracy: 90.40, Test time: 63.91\n",
      "Epoch [1/1], Step [48400/89295], Accuracy: 90.40, Test time: 64.17\n",
      "Epoch [1/1], Step [48500/89295], Accuracy: 90.40, Test time: 64.30\n",
      "Epoch [1/1], Step [48600/89295], Accuracy: 90.39, Test time: 64.37\n",
      "Epoch [1/1], Step [48700/89295], Accuracy: 90.39, Test time: 64.55\n",
      "Epoch [1/1], Step [48800/89295], Accuracy: 90.38, Test time: 64.61\n",
      "Epoch [1/1], Step [48900/89295], Accuracy: 90.38, Test time: 64.66\n",
      "Epoch [1/1], Step [49000/89295], Accuracy: 90.38, Test time: 64.89\n",
      "Epoch [1/1], Step [49100/89295], Accuracy: 90.38, Test time: 65.05\n",
      "Epoch [1/1], Step [49200/89295], Accuracy: 90.38, Test time: 65.11\n",
      "Epoch [1/1], Step [49300/89295], Accuracy: 90.36, Test time: 65.16\n",
      "Epoch [1/1], Step [49400/89295], Accuracy: 90.36, Test time: 65.21\n",
      "Epoch [1/1], Step [49500/89295], Accuracy: 90.35, Test time: 65.28\n",
      "Epoch [1/1], Step [49600/89295], Accuracy: 90.35, Test time: 65.58\n",
      "Epoch [1/1], Step [49700/89295], Accuracy: 90.34, Test time: 65.71\n",
      "Epoch [1/1], Step [49800/89295], Accuracy: 90.34, Test time: 65.76\n",
      "Epoch [1/1], Step [49900/89295], Accuracy: 90.33, Test time: 65.82\n",
      "Epoch [1/1], Step [50000/89295], Accuracy: 90.34, Test time: 65.97\n",
      "Epoch [1/1], Step [50100/89295], Accuracy: 90.34, Test time: 66.18\n",
      "Epoch [1/1], Step [50200/89295], Accuracy: 90.33, Test time: 66.25\n",
      "Epoch [1/1], Step [50300/89295], Accuracy: 90.33, Test time: 66.30\n",
      "Epoch [1/1], Step [50400/89295], Accuracy: 90.34, Test time: 66.51\n",
      "Epoch [1/1], Step [50500/89295], Accuracy: 90.33, Test time: 66.56\n",
      "Epoch [1/1], Step [50600/89295], Accuracy: 90.32, Test time: 66.61\n",
      "Epoch [1/1], Step [50700/89295], Accuracy: 90.32, Test time: 66.74\n",
      "Epoch [1/1], Step [50800/89295], Accuracy: 90.32, Test time: 67.01\n",
      "Epoch [1/1], Step [50900/89295], Accuracy: 90.33, Test time: 67.17\n",
      "Epoch [1/1], Step [51000/89295], Accuracy: 90.33, Test time: 67.22\n",
      "Epoch [1/1], Step [51100/89295], Accuracy: 90.33, Test time: 67.27\n",
      "Epoch [1/1], Step [51200/89295], Accuracy: 90.32, Test time: 67.48\n",
      "Epoch [1/1], Step [51300/89295], Accuracy: 90.31, Test time: 67.74\n",
      "Epoch [1/1], Step [51400/89295], Accuracy: 90.30, Test time: 67.79\n",
      "Epoch [1/1], Step [51500/89295], Accuracy: 90.30, Test time: 67.96\n",
      "Epoch [1/1], Step [51600/89295], Accuracy: 90.30, Test time: 68.02\n",
      "Epoch [1/1], Step [51700/89295], Accuracy: 90.30, Test time: 68.07\n",
      "Epoch [1/1], Step [51800/89295], Accuracy: 90.30, Test time: 68.13\n",
      "Epoch [1/1], Step [51900/89295], Accuracy: 90.30, Test time: 68.23\n",
      "Epoch [1/1], Step [52000/89295], Accuracy: 90.30, Test time: 68.55\n",
      "Epoch [1/1], Step [52100/89295], Accuracy: 90.31, Test time: 68.67\n",
      "Epoch [1/1], Step [52200/89295], Accuracy: 90.30, Test time: 68.72\n",
      "Epoch [1/1], Step [52300/89295], Accuracy: 90.30, Test time: 68.76\n",
      "Epoch [1/1], Step [52400/89295], Accuracy: 90.30, Test time: 69.09\n",
      "Epoch [1/1], Step [52500/89295], Accuracy: 90.30, Test time: 69.16\n",
      "Epoch [1/1], Step [52600/89295], Accuracy: 90.31, Test time: 69.21\n",
      "Epoch [1/1], Step [52700/89295], Accuracy: 90.30, Test time: 69.27\n",
      "Epoch [1/1], Step [52800/89295], Accuracy: 90.31, Test time: 69.31\n",
      "Epoch [1/1], Step [52900/89295], Accuracy: 90.30, Test time: 69.47\n",
      "Epoch [1/1], Step [53000/89295], Accuracy: 90.30, Test time: 69.81\n",
      "Epoch [1/1], Step [53100/89295], Accuracy: 90.31, Test time: 69.86\n",
      "Epoch [1/1], Step [53200/89295], Accuracy: 90.30, Test time: 69.91\n",
      "Epoch [1/1], Step [53300/89295], Accuracy: 90.30, Test time: 70.03\n",
      "Epoch [1/1], Step [53400/89295], Accuracy: 90.30, Test time: 70.16\n",
      "Epoch [1/1], Step [53500/89295], Accuracy: 90.30, Test time: 70.21\n",
      "Epoch [1/1], Step [53600/89295], Accuracy: 90.30, Test time: 70.27\n",
      "Epoch [1/1], Step [53700/89295], Accuracy: 90.30, Test time: 70.39\n",
      "Epoch [1/1], Step [53800/89295], Accuracy: 90.30, Test time: 70.67\n",
      "Epoch [1/1], Step [53900/89295], Accuracy: 90.29, Test time: 70.74\n",
      "Epoch [1/1], Step [54000/89295], Accuracy: 90.28, Test time: 70.79\n",
      "Epoch [1/1], Step [54100/89295], Accuracy: 90.27, Test time: 70.84\n",
      "Epoch [1/1], Step [54200/89295], Accuracy: 90.27, Test time: 70.97\n",
      "Epoch [1/1], Step [54300/89295], Accuracy: 90.27, Test time: 71.22\n",
      "Epoch [1/1], Step [54400/89295], Accuracy: 90.27, Test time: 71.26\n",
      "Epoch [1/1], Step [54500/89295], Accuracy: 90.27, Test time: 71.31\n",
      "Epoch [1/1], Step [54600/89295], Accuracy: 90.26, Test time: 71.37\n",
      "Epoch [1/1], Step [54700/89295], Accuracy: 90.27, Test time: 71.41\n",
      "Epoch [1/1], Step [54800/89295], Accuracy: 90.26, Test time: 71.76\n",
      "Epoch [1/1], Step [54900/89295], Accuracy: 90.26, Test time: 71.87\n",
      "Epoch [1/1], Step [55000/89295], Accuracy: 90.25, Test time: 71.91\n",
      "Epoch [1/1], Step [55100/89295], Accuracy: 90.24, Test time: 71.96\n",
      "Epoch [1/1], Step [55200/89295], Accuracy: 90.24, Test time: 72.16\n",
      "Epoch [1/1], Step [55300/89295], Accuracy: 90.24, Test time: 72.40\n",
      "Epoch [1/1], Step [55400/89295], Accuracy: 90.23, Test time: 72.46\n",
      "Epoch [1/1], Step [55500/89295], Accuracy: 90.23, Test time: 72.53\n",
      "Epoch [1/1], Step [55600/89295], Accuracy: 90.24, Test time: 72.64\n",
      "Epoch [1/1], Step [55700/89295], Accuracy: 90.25, Test time: 72.76\n",
      "Epoch [1/1], Step [55800/89295], Accuracy: 90.25, Test time: 72.82\n",
      "Epoch [1/1], Step [55900/89295], Accuracy: 90.24, Test time: 73.01\n",
      "Epoch [1/1], Step [56000/89295], Accuracy: 90.24, Test time: 73.12\n",
      "Epoch [1/1], Step [56100/89295], Accuracy: 90.24, Test time: 73.19\n",
      "Epoch [1/1], Step [56200/89295], Accuracy: 90.24, Test time: 73.35\n",
      "Epoch [1/1], Step [56300/89295], Accuracy: 90.24, Test time: 73.41\n",
      "Epoch [1/1], Step [56400/89295], Accuracy: 90.24, Test time: 73.59\n",
      "Epoch [1/1], Step [56500/89295], Accuracy: 90.24, Test time: 73.70\n",
      "Epoch [1/1], Step [56600/89295], Accuracy: 90.25, Test time: 73.84\n",
      "Epoch [1/1], Step [56700/89295], Accuracy: 90.25, Test time: 73.95\n",
      "Epoch [1/1], Step [56800/89295], Accuracy: 90.24, Test time: 74.01\n",
      "Epoch [1/1], Step [56900/89295], Accuracy: 90.25, Test time: 74.16\n",
      "Epoch [1/1], Step [57000/89295], Accuracy: 90.25, Test time: 74.26\n",
      "Epoch [1/1], Step [57100/89295], Accuracy: 90.26, Test time: 74.40\n",
      "Epoch [1/1], Step [57200/89295], Accuracy: 90.26, Test time: 74.50\n",
      "Epoch [1/1], Step [57300/89295], Accuracy: 90.26, Test time: 74.64\n",
      "Epoch [1/1], Step [57400/89295], Accuracy: 90.27, Test time: 74.71\n",
      "Epoch [1/1], Step [57500/89295], Accuracy: 90.26, Test time: 74.84\n",
      "Epoch [1/1], Step [57600/89295], Accuracy: 90.26, Test time: 74.92\n",
      "Epoch [1/1], Step [57700/89295], Accuracy: 90.26, Test time: 75.24\n",
      "Epoch [1/1], Step [57800/89295], Accuracy: 90.27, Test time: 75.29\n",
      "Epoch [1/1], Step [57900/89295], Accuracy: 90.28, Test time: 75.35\n",
      "Epoch [1/1], Step [58000/89295], Accuracy: 90.28, Test time: 75.39\n",
      "Epoch [1/1], Step [58100/89295], Accuracy: 90.28, Test time: 75.65\n",
      "Epoch [1/1], Step [58200/89295], Accuracy: 90.27, Test time: 75.75\n",
      "Epoch [1/1], Step [58300/89295], Accuracy: 90.28, Test time: 75.83\n",
      "Epoch [1/1], Step [58400/89295], Accuracy: 90.28, Test time: 75.95\n",
      "Epoch [1/1], Step [58500/89295], Accuracy: 90.28, Test time: 76.16\n",
      "Epoch [1/1], Step [58600/89295], Accuracy: 90.28, Test time: 76.26\n",
      "Epoch [1/1], Step [58700/89295], Accuracy: 90.29, Test time: 76.34\n",
      "Epoch [1/1], Step [58800/89295], Accuracy: 90.29, Test time: 76.40\n",
      "Epoch [1/1], Step [58900/89295], Accuracy: 90.29, Test time: 76.62\n",
      "Epoch [1/1], Step [59000/89295], Accuracy: 90.28, Test time: 76.69\n",
      "Epoch [1/1], Step [59100/89295], Accuracy: 90.29, Test time: 76.78\n",
      "Epoch [1/1], Step [59200/89295], Accuracy: 90.28, Test time: 76.87\n",
      "Epoch [1/1], Step [59300/89295], Accuracy: 90.28, Test time: 77.09\n",
      "Epoch [1/1], Step [59400/89295], Accuracy: 90.27, Test time: 77.16\n",
      "Epoch [1/1], Step [59500/89295], Accuracy: 90.27, Test time: 77.22\n",
      "Epoch [1/1], Step [59600/89295], Accuracy: 90.26, Test time: 77.38\n",
      "Epoch [1/1], Step [59700/89295], Accuracy: 90.25, Test time: 77.43\n",
      "Epoch [1/1], Step [59800/89295], Accuracy: 90.25, Test time: 77.48\n",
      "Epoch [1/1], Step [59900/89295], Accuracy: 90.25, Test time: 77.55\n",
      "Epoch [1/1], Step [60000/89295], Accuracy: 90.25, Test time: 77.70\n",
      "Epoch [1/1], Step [60100/89295], Accuracy: 90.26, Test time: 77.83\n",
      "Epoch [1/1], Step [60200/89295], Accuracy: 90.26, Test time: 78.07\n",
      "Epoch [1/1], Step [60300/89295], Accuracy: 90.26, Test time: 78.16\n",
      "Epoch [1/1], Step [60400/89295], Accuracy: 90.26, Test time: 78.22\n",
      "Epoch [1/1], Step [60500/89295], Accuracy: 90.27, Test time: 78.26\n",
      "Epoch [1/1], Step [60600/89295], Accuracy: 90.27, Test time: 78.31\n",
      "Epoch [1/1], Step [60700/89295], Accuracy: 90.27, Test time: 78.35\n",
      "Epoch [1/1], Step [60800/89295], Accuracy: 90.28, Test time: 78.76\n",
      "Epoch [1/1], Step [60900/89295], Accuracy: 90.28, Test time: 78.98\n",
      "Epoch [1/1], Step [61000/89295], Accuracy: 90.29, Test time: 79.03\n",
      "Epoch [1/1], Step [61100/89295], Accuracy: 90.30, Test time: 79.07\n",
      "Epoch [1/1], Step [61200/89295], Accuracy: 90.29, Test time: 79.12\n",
      "Epoch [1/1], Step [61300/89295], Accuracy: 90.30, Test time: 79.18\n",
      "Epoch [1/1], Step [61400/89295], Accuracy: 90.30, Test time: 79.45\n",
      "Epoch [1/1], Step [61500/89295], Accuracy: 90.30, Test time: 79.55\n",
      "Epoch [1/1], Step [61600/89295], Accuracy: 90.31, Test time: 79.60\n",
      "Epoch [1/1], Step [61700/89295], Accuracy: 90.31, Test time: 79.65\n",
      "Epoch [1/1], Step [61800/89295], Accuracy: 90.31, Test time: 79.70\n",
      "Epoch [1/1], Step [61900/89295], Accuracy: 90.32, Test time: 79.79\n",
      "Epoch [1/1], Step [62000/89295], Accuracy: 90.31, Test time: 80.09\n",
      "Epoch [1/1], Step [62100/89295], Accuracy: 90.32, Test time: 80.32\n",
      "Epoch [1/1], Step [62200/89295], Accuracy: 90.32, Test time: 80.38\n",
      "Epoch [1/1], Step [62300/89295], Accuracy: 90.32, Test time: 80.43\n",
      "Epoch [1/1], Step [62400/89295], Accuracy: 90.32, Test time: 80.48\n",
      "Epoch [1/1], Step [62500/89295], Accuracy: 90.31, Test time: 80.52\n",
      "Epoch [1/1], Step [62600/89295], Accuracy: 90.32, Test time: 80.60\n",
      "Epoch [1/1], Step [62700/89295], Accuracy: 90.32, Test time: 80.84\n",
      "Epoch [1/1], Step [62800/89295], Accuracy: 90.31, Test time: 81.06\n",
      "Epoch [1/1], Step [62900/89295], Accuracy: 90.31, Test time: 81.11\n",
      "Epoch [1/1], Step [63000/89295], Accuracy: 90.31, Test time: 81.16\n",
      "Epoch [1/1], Step [63100/89295], Accuracy: 90.32, Test time: 81.20\n",
      "Epoch [1/1], Step [63200/89295], Accuracy: 90.32, Test time: 81.39\n",
      "Epoch [1/1], Step [63300/89295], Accuracy: 90.32, Test time: 81.58\n",
      "Epoch [1/1], Step [63400/89295], Accuracy: 90.31, Test time: 81.63\n",
      "Epoch [1/1], Step [63500/89295], Accuracy: 90.32, Test time: 81.68\n",
      "Epoch [1/1], Step [63600/89295], Accuracy: 90.32, Test time: 81.73\n",
      "Epoch [1/1], Step [63700/89295], Accuracy: 90.32, Test time: 81.77\n",
      "Epoch [1/1], Step [63800/89295], Accuracy: 90.32, Test time: 82.10\n",
      "Epoch [1/1], Step [63900/89295], Accuracy: 90.32, Test time: 82.23\n",
      "Epoch [1/1], Step [64000/89295], Accuracy: 90.32, Test time: 82.28\n",
      "Epoch [1/1], Step [64100/89295], Accuracy: 90.32, Test time: 82.32\n",
      "Epoch [1/1], Step [64200/89295], Accuracy: 90.32, Test time: 82.42\n",
      "Epoch [1/1], Step [64300/89295], Accuracy: 90.32, Test time: 82.67\n",
      "Epoch [1/1], Step [64400/89295], Accuracy: 90.32, Test time: 82.74\n",
      "Epoch [1/1], Step [64500/89295], Accuracy: 90.32, Test time: 82.79\n",
      "Epoch [1/1], Step [64600/89295], Accuracy: 90.31, Test time: 82.83\n",
      "Epoch [1/1], Step [64700/89295], Accuracy: 90.32, Test time: 83.07\n",
      "Epoch [1/1], Step [64800/89295], Accuracy: 90.32, Test time: 83.30\n",
      "Epoch [1/1], Step [64900/89295], Accuracy: 90.31, Test time: 83.35\n",
      "Epoch [1/1], Step [65000/89295], Accuracy: 90.31, Test time: 83.40\n",
      "Epoch [1/1], Step [65100/89295], Accuracy: 90.31, Test time: 83.57\n",
      "Epoch [1/1], Step [65200/89295], Accuracy: 90.31, Test time: 83.61\n",
      "Epoch [1/1], Step [65300/89295], Accuracy: 90.32, Test time: 83.66\n",
      "Epoch [1/1], Step [65400/89295], Accuracy: 90.31, Test time: 83.71\n",
      "Epoch [1/1], Step [65500/89295], Accuracy: 90.31, Test time: 83.96\n",
      "Epoch [1/1], Step [65600/89295], Accuracy: 90.31, Test time: 84.21\n",
      "Epoch [1/1], Step [65700/89295], Accuracy: 90.31, Test time: 84.27\n",
      "Epoch [1/1], Step [65800/89295], Accuracy: 90.32, Test time: 84.31\n",
      "Epoch [1/1], Step [65900/89295], Accuracy: 90.32, Test time: 84.35\n",
      "Epoch [1/1], Step [66000/89295], Accuracy: 90.32, Test time: 84.61\n",
      "Epoch [1/1], Step [66100/89295], Accuracy: 90.33, Test time: 84.78\n",
      "Epoch [1/1], Step [66200/89295], Accuracy: 90.32, Test time: 84.82\n",
      "Epoch [1/1], Step [66300/89295], Accuracy: 90.33, Test time: 84.87\n",
      "Epoch [1/1], Step [66400/89295], Accuracy: 90.33, Test time: 84.91\n",
      "Epoch [1/1], Step [66500/89295], Accuracy: 90.34, Test time: 85.21\n",
      "Epoch [1/1], Step [66600/89295], Accuracy: 90.34, Test time: 85.32\n",
      "Epoch [1/1], Step [66700/89295], Accuracy: 90.34, Test time: 85.37\n",
      "Epoch [1/1], Step [66800/89295], Accuracy: 90.34, Test time: 85.41\n",
      "Epoch [1/1], Step [66900/89295], Accuracy: 90.34, Test time: 85.46\n",
      "Epoch [1/1], Step [67000/89295], Accuracy: 90.34, Test time: 85.79\n",
      "Epoch [1/1], Step [67100/89295], Accuracy: 90.35, Test time: 85.90\n",
      "Epoch [1/1], Step [67200/89295], Accuracy: 90.35, Test time: 85.94\n",
      "Epoch [1/1], Step [67300/89295], Accuracy: 90.34, Test time: 85.99\n",
      "Epoch [1/1], Step [67400/89295], Accuracy: 90.33, Test time: 86.03\n",
      "Epoch [1/1], Step [67500/89295], Accuracy: 90.34, Test time: 86.22\n",
      "Epoch [1/1], Step [67600/89295], Accuracy: 90.33, Test time: 86.44\n",
      "Epoch [1/1], Step [67700/89295], Accuracy: 90.33, Test time: 86.50\n",
      "Epoch [1/1], Step [67800/89295], Accuracy: 90.33, Test time: 86.54\n",
      "Epoch [1/1], Step [67900/89295], Accuracy: 90.32, Test time: 86.58\n",
      "Epoch [1/1], Step [68000/89295], Accuracy: 90.33, Test time: 86.87\n",
      "Epoch [1/1], Step [68100/89295], Accuracy: 90.33, Test time: 87.03\n",
      "Epoch [1/1], Step [68200/89295], Accuracy: 90.33, Test time: 87.08\n",
      "Epoch [1/1], Step [68300/89295], Accuracy: 90.33, Test time: 87.12\n",
      "Epoch [1/1], Step [68400/89295], Accuracy: 90.34, Test time: 87.17\n",
      "Epoch [1/1], Step [68500/89295], Accuracy: 90.33, Test time: 87.40\n",
      "Epoch [1/1], Step [68600/89295], Accuracy: 90.33, Test time: 87.59\n",
      "Epoch [1/1], Step [68700/89295], Accuracy: 90.32, Test time: 87.63\n",
      "Epoch [1/1], Step [68800/89295], Accuracy: 90.32, Test time: 87.67\n",
      "Epoch [1/1], Step [68900/89295], Accuracy: 90.31, Test time: 87.71\n",
      "Epoch [1/1], Step [69000/89295], Accuracy: 90.31, Test time: 88.01\n",
      "Epoch [1/1], Step [69100/89295], Accuracy: 90.31, Test time: 88.17\n",
      "Epoch [1/1], Step [69200/89295], Accuracy: 90.31, Test time: 88.21\n",
      "Epoch [1/1], Step [69300/89295], Accuracy: 90.30, Test time: 88.26\n",
      "Epoch [1/1], Step [69400/89295], Accuracy: 90.31, Test time: 88.30\n",
      "Epoch [1/1], Step [69500/89295], Accuracy: 90.31, Test time: 88.51\n",
      "Epoch [1/1], Step [69600/89295], Accuracy: 90.30, Test time: 88.76\n",
      "Epoch [1/1], Step [69700/89295], Accuracy: 90.31, Test time: 88.80\n",
      "Epoch [1/1], Step [69800/89295], Accuracy: 90.31, Test time: 88.85\n",
      "Epoch [1/1], Step [69900/89295], Accuracy: 90.31, Test time: 88.97\n",
      "Epoch [1/1], Step [70000/89295], Accuracy: 90.32, Test time: 89.17\n",
      "Epoch [1/1], Step [70100/89295], Accuracy: 90.33, Test time: 89.21\n",
      "Epoch [1/1], Step [70200/89295], Accuracy: 90.32, Test time: 89.27\n",
      "Epoch [1/1], Step [70300/89295], Accuracy: 90.32, Test time: 89.42\n",
      "Epoch [1/1], Step [70400/89295], Accuracy: 90.32, Test time: 89.66\n",
      "Epoch [1/1], Step [70500/89295], Accuracy: 90.33, Test time: 89.76\n",
      "Epoch [1/1], Step [70600/89295], Accuracy: 90.33, Test time: 89.89\n",
      "Epoch [1/1], Step [70700/89295], Accuracy: 90.34, Test time: 89.95\n",
      "Epoch [1/1], Step [70800/89295], Accuracy: 90.33, Test time: 90.00\n",
      "Epoch [1/1], Step [70900/89295], Accuracy: 90.32, Test time: 90.04\n",
      "Epoch [1/1], Step [71000/89295], Accuracy: 90.33, Test time: 90.08\n",
      "Epoch [1/1], Step [71100/89295], Accuracy: 90.32, Test time: 90.29\n",
      "Epoch [1/1], Step [71200/89295], Accuracy: 90.32, Test time: 90.54\n",
      "Epoch [1/1], Step [71300/89295], Accuracy: 90.32, Test time: 90.58\n",
      "Epoch [1/1], Step [71400/89295], Accuracy: 90.32, Test time: 90.62\n",
      "Epoch [1/1], Step [71500/89295], Accuracy: 90.31, Test time: 90.66\n",
      "Epoch [1/1], Step [71600/89295], Accuracy: 90.32, Test time: 90.71\n",
      "Epoch [1/1], Step [71700/89295], Accuracy: 90.32, Test time: 90.88\n",
      "Epoch [1/1], Step [71800/89295], Accuracy: 90.32, Test time: 91.10\n",
      "Epoch [1/1], Step [71900/89295], Accuracy: 90.31, Test time: 91.21\n",
      "Epoch [1/1], Step [72000/89295], Accuracy: 90.31, Test time: 91.25\n",
      "Epoch [1/1], Step [72100/89295], Accuracy: 90.31, Test time: 91.29\n",
      "Epoch [1/1], Step [72200/89295], Accuracy: 90.31, Test time: 91.49\n",
      "Epoch [1/1], Step [72300/89295], Accuracy: 90.31, Test time: 91.72\n",
      "Epoch [1/1], Step [72400/89295], Accuracy: 90.31, Test time: 91.76\n",
      "Epoch [1/1], Step [72500/89295], Accuracy: 90.31, Test time: 91.81\n",
      "Epoch [1/1], Step [72600/89295], Accuracy: 90.32, Test time: 91.85\n",
      "Epoch [1/1], Step [72700/89295], Accuracy: 90.31, Test time: 92.14\n",
      "Epoch [1/1], Step [72800/89295], Accuracy: 90.32, Test time: 92.24\n",
      "Epoch [1/1], Step [72900/89295], Accuracy: 90.32, Test time: 92.28\n",
      "Epoch [1/1], Step [73000/89295], Accuracy: 90.33, Test time: 92.32\n",
      "Epoch [1/1], Step [73100/89295], Accuracy: 90.33, Test time: 92.36\n",
      "Epoch [1/1], Step [73200/89295], Accuracy: 90.33, Test time: 92.48\n",
      "Epoch [1/1], Step [73300/89295], Accuracy: 90.34, Test time: 92.70\n",
      "Epoch [1/1], Step [73400/89295], Accuracy: 90.34, Test time: 92.92\n",
      "Epoch [1/1], Step [73500/89295], Accuracy: 90.33, Test time: 92.97\n",
      "Epoch [1/1], Step [73600/89295], Accuracy: 90.33, Test time: 93.01\n",
      "Epoch [1/1], Step [73700/89295], Accuracy: 90.33, Test time: 93.05\n",
      "Epoch [1/1], Step [73800/89295], Accuracy: 90.32, Test time: 93.10\n",
      "Epoch [1/1], Step [73900/89295], Accuracy: 90.32, Test time: 93.18\n",
      "Epoch [1/1], Step [74000/89295], Accuracy: 90.32, Test time: 93.44\n",
      "Epoch [1/1], Step [74100/89295], Accuracy: 90.31, Test time: 93.68\n",
      "Epoch [1/1], Step [74200/89295], Accuracy: 90.32, Test time: 93.74\n",
      "Epoch [1/1], Step [74300/89295], Accuracy: 90.31, Test time: 93.79\n",
      "Epoch [1/1], Step [74400/89295], Accuracy: 90.31, Test time: 93.93\n",
      "Epoch [1/1], Step [74500/89295], Accuracy: 90.31, Test time: 94.12\n",
      "Epoch [1/1], Step [74600/89295], Accuracy: 90.31, Test time: 94.16\n",
      "Epoch [1/1], Step [74700/89295], Accuracy: 90.31, Test time: 94.20\n",
      "Epoch [1/1], Step [74800/89295], Accuracy: 90.30, Test time: 94.25\n",
      "Epoch [1/1], Step [74900/89295], Accuracy: 90.30, Test time: 94.47\n",
      "Epoch [1/1], Step [75000/89295], Accuracy: 90.30, Test time: 94.59\n",
      "Epoch [1/1], Step [75100/89295], Accuracy: 90.31, Test time: 94.63\n",
      "Epoch [1/1], Step [75200/89295], Accuracy: 90.31, Test time: 94.67\n",
      "Epoch [1/1], Step [75300/89295], Accuracy: 90.31, Test time: 94.74\n",
      "Epoch [1/1], Step [75400/89295], Accuracy: 90.30, Test time: 94.96\n",
      "Epoch [1/1], Step [75500/89295], Accuracy: 90.31, Test time: 95.15\n",
      "Epoch [1/1], Step [75600/89295], Accuracy: 90.30, Test time: 95.19\n",
      "Epoch [1/1], Step [75700/89295], Accuracy: 90.30, Test time: 95.24\n",
      "Epoch [1/1], Step [75800/89295], Accuracy: 90.30, Test time: 95.39\n",
      "Epoch [1/1], Step [75900/89295], Accuracy: 90.29, Test time: 95.66\n",
      "Epoch [1/1], Step [76000/89295], Accuracy: 90.30, Test time: 95.73\n",
      "Epoch [1/1], Step [76100/89295], Accuracy: 90.30, Test time: 95.77\n",
      "Epoch [1/1], Step [76200/89295], Accuracy: 90.29, Test time: 95.84\n",
      "Epoch [1/1], Step [76300/89295], Accuracy: 90.29, Test time: 95.96\n",
      "Epoch [1/1], Step [76400/89295], Accuracy: 90.29, Test time: 96.18\n",
      "Epoch [1/1], Step [76500/89295], Accuracy: 90.30, Test time: 96.27\n",
      "Epoch [1/1], Step [76600/89295], Accuracy: 90.30, Test time: 96.31\n",
      "Epoch [1/1], Step [76700/89295], Accuracy: 90.30, Test time: 96.35\n",
      "Epoch [1/1], Step [76800/89295], Accuracy: 90.30, Test time: 96.40\n",
      "Epoch [1/1], Step [76900/89295], Accuracy: 90.30, Test time: 96.55\n",
      "Epoch [1/1], Step [77000/89295], Accuracy: 90.29, Test time: 96.76\n",
      "Epoch [1/1], Step [77100/89295], Accuracy: 90.29, Test time: 96.89\n",
      "Epoch [1/1], Step [77200/89295], Accuracy: 90.30, Test time: 96.93\n",
      "Epoch [1/1], Step [77300/89295], Accuracy: 90.30, Test time: 96.97\n",
      "Epoch [1/1], Step [77400/89295], Accuracy: 90.31, Test time: 97.20\n",
      "Epoch [1/1], Step [77500/89295], Accuracy: 90.31, Test time: 97.37\n",
      "Epoch [1/1], Step [77600/89295], Accuracy: 90.31, Test time: 97.42\n",
      "Epoch [1/1], Step [77700/89295], Accuracy: 90.32, Test time: 97.46\n",
      "Epoch [1/1], Step [77800/89295], Accuracy: 90.31, Test time: 97.50\n",
      "Epoch [1/1], Step [77900/89295], Accuracy: 90.31, Test time: 97.54\n",
      "Epoch [1/1], Step [78000/89295], Accuracy: 90.31, Test time: 97.88\n",
      "Epoch [1/1], Step [78100/89295], Accuracy: 90.31, Test time: 97.99\n",
      "Epoch [1/1], Step [78200/89295], Accuracy: 90.31, Test time: 98.03\n",
      "Epoch [1/1], Step [78300/89295], Accuracy: 90.31, Test time: 98.07\n",
      "Epoch [1/1], Step [78400/89295], Accuracy: 90.31, Test time: 98.12\n",
      "Epoch [1/1], Step [78500/89295], Accuracy: 90.30, Test time: 98.42\n",
      "Epoch [1/1], Step [78600/89295], Accuracy: 90.30, Test time: 98.55\n",
      "Epoch [1/1], Step [78700/89295], Accuracy: 90.30, Test time: 98.59\n",
      "Epoch [1/1], Step [78800/89295], Accuracy: 90.29, Test time: 98.63\n",
      "Epoch [1/1], Step [78900/89295], Accuracy: 90.30, Test time: 98.68\n",
      "Epoch [1/1], Step [79000/89295], Accuracy: 90.30, Test time: 98.94\n",
      "Epoch [1/1], Step [79100/89295], Accuracy: 90.30, Test time: 99.20\n",
      "Epoch [1/1], Step [79200/89295], Accuracy: 90.30, Test time: 99.25\n",
      "Epoch [1/1], Step [79300/89295], Accuracy: 90.30, Test time: 99.42\n",
      "Epoch [1/1], Step [79400/89295], Accuracy: 90.29, Test time: 99.46\n",
      "Epoch [1/1], Step [79500/89295], Accuracy: 90.29, Test time: 99.51\n",
      "Epoch [1/1], Step [79600/89295], Accuracy: 90.29, Test time: 99.62\n",
      "Epoch [1/1], Step [79700/89295], Accuracy: 90.28, Test time: 99.86\n",
      "Epoch [1/1], Step [79800/89295], Accuracy: 90.28, Test time: 99.96\n",
      "Epoch [1/1], Step [79900/89295], Accuracy: 90.28, Test time: 100.00\n",
      "Epoch [1/1], Step [80000/89295], Accuracy: 90.28, Test time: 100.05\n",
      "Epoch [1/1], Step [80100/89295], Accuracy: 90.27, Test time: 100.09\n",
      "Epoch [1/1], Step [80200/89295], Accuracy: 90.28, Test time: 100.31\n",
      "Epoch [1/1], Step [80300/89295], Accuracy: 90.28, Test time: 100.58\n",
      "Epoch [1/1], Step [80400/89295], Accuracy: 90.28, Test time: 100.67\n",
      "Epoch [1/1], Step [80500/89295], Accuracy: 90.27, Test time: 100.71\n",
      "Epoch [1/1], Step [80600/89295], Accuracy: 90.27, Test time: 100.76\n",
      "Epoch [1/1], Step [80700/89295], Accuracy: 90.27, Test time: 100.97\n",
      "Epoch [1/1], Step [80800/89295], Accuracy: 90.27, Test time: 101.17\n",
      "Epoch [1/1], Step [80900/89295], Accuracy: 90.27, Test time: 101.21\n",
      "Epoch [1/1], Step [81000/89295], Accuracy: 90.27, Test time: 101.25\n",
      "Epoch [1/1], Step [81100/89295], Accuracy: 90.27, Test time: 101.30\n",
      "Epoch [1/1], Step [81200/89295], Accuracy: 90.28, Test time: 101.60\n",
      "Epoch [1/1], Step [81300/89295], Accuracy: 90.27, Test time: 101.85\n",
      "Epoch [1/1], Step [81400/89295], Accuracy: 90.28, Test time: 101.97\n",
      "Epoch [1/1], Step [81500/89295], Accuracy: 90.28, Test time: 102.01\n",
      "Epoch [1/1], Step [81600/89295], Accuracy: 90.28, Test time: 102.05\n",
      "Epoch [1/1], Step [81700/89295], Accuracy: 90.28, Test time: 102.10\n",
      "Epoch [1/1], Step [81800/89295], Accuracy: 90.27, Test time: 102.22\n",
      "Epoch [1/1], Step [81900/89295], Accuracy: 90.27, Test time: 102.48\n",
      "Epoch [1/1], Step [82000/89295], Accuracy: 90.27, Test time: 102.53\n",
      "Epoch [1/1], Step [82100/89295], Accuracy: 90.28, Test time: 102.57\n",
      "Epoch [1/1], Step [82200/89295], Accuracy: 90.27, Test time: 102.63\n",
      "Epoch [1/1], Step [82300/89295], Accuracy: 90.27, Test time: 102.75\n",
      "Epoch [1/1], Step [82400/89295], Accuracy: 90.26, Test time: 103.04\n",
      "Epoch [1/1], Step [82500/89295], Accuracy: 90.26, Test time: 103.18\n",
      "Epoch [1/1], Step [82600/89295], Accuracy: 90.26, Test time: 103.33\n",
      "Epoch [1/1], Step [82700/89295], Accuracy: 90.26, Test time: 103.45\n",
      "Epoch [1/1], Step [82800/89295], Accuracy: 90.26, Test time: 103.49\n",
      "Epoch [1/1], Step [82900/89295], Accuracy: 90.27, Test time: 103.53\n",
      "Epoch [1/1], Step [83000/89295], Accuracy: 90.26, Test time: 103.58\n",
      "Epoch [1/1], Step [83100/89295], Accuracy: 90.26, Test time: 103.81\n",
      "Epoch [1/1], Step [83200/89295], Accuracy: 90.26, Test time: 104.03\n",
      "Epoch [1/1], Step [83300/89295], Accuracy: 90.25, Test time: 104.07\n",
      "Epoch [1/1], Step [83400/89295], Accuracy: 90.25, Test time: 104.11\n",
      "Epoch [1/1], Step [83500/89295], Accuracy: 90.25, Test time: 104.15\n",
      "Epoch [1/1], Step [83600/89295], Accuracy: 90.25, Test time: 104.43\n",
      "Epoch [1/1], Step [83700/89295], Accuracy: 90.25, Test time: 104.47\n",
      "Epoch [1/1], Step [83800/89295], Accuracy: 90.26, Test time: 104.51\n",
      "Epoch [1/1], Step [83900/89295], Accuracy: 90.25, Test time: 104.56\n",
      "Epoch [1/1], Step [84000/89295], Accuracy: 90.26, Test time: 104.60\n",
      "Epoch [1/1], Step [84100/89295], Accuracy: 90.25, Test time: 104.95\n",
      "Epoch [1/1], Step [84200/89295], Accuracy: 90.26, Test time: 105.23\n",
      "Epoch [1/1], Step [84300/89295], Accuracy: 90.26, Test time: 105.29\n",
      "Epoch [1/1], Step [84400/89295], Accuracy: 90.25, Test time: 105.33\n",
      "Epoch [1/1], Step [84500/89295], Accuracy: 90.26, Test time: 105.37\n",
      "Epoch [1/1], Step [84600/89295], Accuracy: 90.27, Test time: 105.42\n",
      "Epoch [1/1], Step [84700/89295], Accuracy: 90.26, Test time: 105.74\n",
      "Epoch [1/1], Step [84800/89295], Accuracy: 90.26, Test time: 105.82\n",
      "Epoch [1/1], Step [84900/89295], Accuracy: 90.26, Test time: 105.86\n",
      "Epoch [1/1], Step [85000/89295], Accuracy: 90.25, Test time: 105.91\n",
      "Epoch [1/1], Step [85100/89295], Accuracy: 90.25, Test time: 105.95\n",
      "Epoch [1/1], Step [85200/89295], Accuracy: 90.25, Test time: 106.21\n",
      "Epoch [1/1], Step [85300/89295], Accuracy: 90.25, Test time: 106.38\n",
      "Epoch [1/1], Step [85400/89295], Accuracy: 90.25, Test time: 106.42\n",
      "Epoch [1/1], Step [85500/89295], Accuracy: 90.25, Test time: 106.47\n",
      "Epoch [1/1], Step [85600/89295], Accuracy: 90.24, Test time: 106.51\n",
      "Epoch [1/1], Step [85700/89295], Accuracy: 90.25, Test time: 106.70\n",
      "Epoch [1/1], Step [85800/89295], Accuracy: 90.25, Test time: 106.90\n",
      "Epoch [1/1], Step [85900/89295], Accuracy: 90.25, Test time: 106.94\n",
      "Epoch [1/1], Step [86000/89295], Accuracy: 90.26, Test time: 106.98\n",
      "Epoch [1/1], Step [86100/89295], Accuracy: 90.26, Test time: 107.02\n",
      "Epoch [1/1], Step [86200/89295], Accuracy: 90.26, Test time: 107.07\n",
      "Epoch [1/1], Step [86300/89295], Accuracy: 90.26, Test time: 107.23\n",
      "Epoch [1/1], Step [86400/89295], Accuracy: 90.25, Test time: 107.50\n",
      "Epoch [1/1], Step [86500/89295], Accuracy: 90.26, Test time: 107.58\n",
      "Epoch [1/1], Step [86600/89295], Accuracy: 90.25, Test time: 107.62\n",
      "Epoch [1/1], Step [86700/89295], Accuracy: 90.26, Test time: 107.66\n",
      "Epoch [1/1], Step [86800/89295], Accuracy: 90.25, Test time: 107.71\n",
      "Epoch [1/1], Step [86900/89295], Accuracy: 90.25, Test time: 107.96\n",
      "Epoch [1/1], Step [87000/89295], Accuracy: 90.25, Test time: 108.20\n",
      "Epoch [1/1], Step [87100/89295], Accuracy: 90.25, Test time: 108.24\n",
      "Epoch [1/1], Step [87200/89295], Accuracy: 90.26, Test time: 108.29\n",
      "Epoch [1/1], Step [87300/89295], Accuracy: 90.27, Test time: 108.39\n",
      "Epoch [1/1], Step [87400/89295], Accuracy: 90.27, Test time: 108.52\n",
      "Epoch [1/1], Step [87500/89295], Accuracy: 90.27, Test time: 108.56\n",
      "Epoch [1/1], Step [87600/89295], Accuracy: 90.27, Test time: 108.62\n",
      "Epoch [1/1], Step [87700/89295], Accuracy: 90.27, Test time: 108.66\n",
      "Epoch [1/1], Step [87800/89295], Accuracy: 90.26, Test time: 108.86\n",
      "Epoch [1/1], Step [87900/89295], Accuracy: 90.27, Test time: 109.11\n",
      "Epoch [1/1], Step [88000/89295], Accuracy: 90.26, Test time: 109.18\n",
      "Epoch [1/1], Step [88100/89295], Accuracy: 90.27, Test time: 109.23\n",
      "Epoch [1/1], Step [88200/89295], Accuracy: 90.27, Test time: 109.27\n",
      "Epoch [1/1], Step [88300/89295], Accuracy: 90.27, Test time: 109.31\n",
      "Epoch [1/1], Step [88400/89295], Accuracy: 90.28, Test time: 109.60\n",
      "Epoch [1/1], Step [88500/89295], Accuracy: 90.28, Test time: 109.74\n",
      "Epoch [1/1], Step [88600/89295], Accuracy: 90.28, Test time: 109.79\n",
      "Epoch [1/1], Step [88700/89295], Accuracy: 90.28, Test time: 109.86\n",
      "Epoch [1/1], Step [88800/89295], Accuracy: 90.28, Test time: 110.04\n",
      "Epoch [1/1], Step [88900/89295], Accuracy: 90.27, Test time: 110.08\n",
      "Epoch [1/1], Step [89000/89295], Accuracy: 90.28, Test time: 110.13\n",
      "Epoch [1/1], Step [89100/89295], Accuracy: 90.27, Test time: 110.28\n",
      "Epoch [1/1], Step [89200/89295], Accuracy: 90.27, Test time: 110.47\n",
      "Accuracy on test set: 90.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Print training statistics\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Accuracy: {:.2f}, Test time: {:.2f}'\n",
    "                      .format(epoch+1, num_epochs, i+1, len(val_loader), 100 * correct / total, (time.time()-start_time)/60))\n",
    "\n",
    "    print('Accuracy on test set: {:.2f}%'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
